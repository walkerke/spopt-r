---
title: "Regionalization with spopt"
format: html
editor: visual
bibliography: references.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
options(tigris_use_cache = TRUE)
```

*Regionalization* refers to the process of grouping smaller geographic units into larger, spatially contiguous regions. Unlike standard clustering methods, regionalization algorithms enforce that resulting regions form connected geographic areas - you can't have a region with disconnected pieces scattered across the map.

This vignette walks through spopt's regionalization algorithms using Census tract data from Dallas, Texas. We'll explore how to build regions that minimize internal heterogeneity while maintaining spatial contiguity and meeting population thresholds.

## When would you use regionalization?

Regionalization solves problems across many fields:

-   **Political redistricting**: Building compact, contiguous districts that balance population
-   **Market segmentation**: Creating sales territories with similar customer characteristics
-   **Health planning**: Aggregating small-area data while preserving spatial relationships
-   **Urban planning**: Delineating neighborhoods based on socioeconomic similarity
-   **Census data analysis**: Addressing differential privacy concerns by aggregating blocks into larger areas

## Getting Census data

Let's start by pulling some demographic data for Census tracts in Dallas County, Texas. We'll use the tidycensus package to get population, median household income, and percentage with a bachelor's degree - variables that might define meaningful neighborhood clusters.

```{r}
library(spopt)
library(tidycensus)
library(tidyverse)
library(sf)
library(mapgl)

dallas <- get_acs(
  geography = "tract",
  variables = c(
    pop = "B01003_001",
    income = "B19013_001",
    bachelors = "DP02_0068P"
  ),
  state = "TX",
  county = "Dallas",
  geometry = TRUE,
  year = 2023,
  output = "wide"
) |>
  filter(!is.na(incomeE), !is.na(bachelorsE))
```

We now have `r nrow(dallas)` Census tracts with population, income, and education data. Let's take a quick look at the geographic distribution of median household income:

```{r}
maplibre_view(dallas, column = "incomeE")
```

The map reveals the familiar spatial pattern of income inequality in Dallas - higher incomes concentrated in the Park Cities north of downtown, with lower incomes in the southern part of the county.

## Max-P regionalization

The *Max-P* algorithm [@duque2012] finds the maximum number of regions such that each region exceeds a specified threshold while minimizing within-region heterogeneity. This is particularly useful when you need regions that meet minimum population requirements for statistical reliability. Recent extensions support compactness constraints [@feng2022] and improved efficiency [@wei2021].

Let's create regions where each must contain at least 50,000 people:

```{r}
maxp_result <- max_p_regions(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  threshold_var = "popE",
  threshold = 50000,
  n_iterations = 100,
  seed = 1983
)

maplibre_view(maxp_result, column = ".region", legend = FALSE)
```

Let's step through the key parameters:

-   `attrs`: The variables used to measure similarity. Tracts with similar income and education levels will be grouped together.
-   `threshold_var`: The variable that must meet the minimum threshold (population in this case).
-   `threshold`: Each region must have at least this many people.
-   `n_iterations`: The algorithm uses a tabu search heuristic; more iterations generally yield better solutions.
-   `seed`: For reproducibility, since the algorithm has stochastic elements.

The result is an sf object with a new `.region` column indicating each tract's assigned region. The algorithm found `r length(unique(maxp_result$.region))` regions, each with at least 50,000 residents.

You can access metadata about the solution through the `spopt` attribute:

```{r}
attr(maxp_result, "spopt")
```

### Spatial weights

By default, all regionalization functions use **queen contiguity** - two tracts are neighbors if they share any boundary point (including corners). You can also use **rook contiguity**, where tracts must share an edge to be neighbors:

```{r}
#| eval: false
maxp_rook <- max_p_regions(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  threshold_var = "popE",
  threshold = 50000,
  weights = "rook",
  n_iterations = 100,
  seed = 1983
)
```

For more control, you can specify weights as a list:

-   `list(type = "knn", k = 6)`: K-nearest neighbors (useful for point data or ensuring connectivity)
-   `list(type = "distance", d = 5000)`: Distance-based weights (units match your CRS)

You can also pass an `nb` object created with spdep or spopt's `sp_weights()` function.

### Compact regions

For applications like sales territories or electoral districts, you may want regions with compact, regular shapes. The `compact` parameter optimizes for compactness in addition to attribute homogeneity:

```{r}
maxp_compact <- max_p_regions(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  threshold_var = "popE",
  threshold = 50000,
  weights = "rook",
  compact = TRUE,
  compact_weight = 0.5,
  n_iterations = 100,
  seed = 1983
)

maplibre_view(maxp_compact, column = ".region", legend = FALSE)
```

The `compact_weight` parameter (0 to 1) controls the trade-off between attribute homogeneity and geometric compactness. Higher values prioritize compact shapes.

## SKATER algorithm

*SKATER* (Spatial K'luster Analysis by Tree Edge Removal) [@assuncao2006] takes a different approach. It first builds a minimum spanning tree connecting all tracts based on their attribute similarity, then iteratively removes edges to create clusters. The algorithm is fast and produces spatially coherent regions.

```{r}
skater_result <- skater(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 6,
  seed = 1983
)

maplibre_view(skater_result, column = ".region", legend = FALSE)
```

SKATER supports a `floor` and `floor_value` parameter if you need minimum population constraints:

```{r}
#| eval: false
skater_constrained <- skater(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 6,
  floor = "popE",
  floor_value = 150000,
  seed = 1983
)
```

## AZP: Automatic Zoning Procedure

The *Automatic Zoning Procedure* (AZP) [@openshaw1977; @openshaw1995] uses local search optimization with three algorithm variants: basic (greedy), tabu search, and simulated annealing.

```{r}
azp_result <- azp(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 20,
  method = "tabu",
  tabu_length = 10,
  max_iterations = 100,
  seed = 1983
)

maplibre_view(azp_result, column = ".region", legend = FALSE)
```

The `method` parameter controls which algorithm variant to use:

-   `"basic"`: Simple greedy local search (fastest)
-   `"tabu"`: Tabu search, which maintains a list of recent moves to avoid getting stuck in local optima
-   `"sa"`: Simulated annealing, which accepts some worse solutions early to explore more of the solution space

For large problems, you may also want to use the simulated annealing variant:

```{r}
#| eval: false
azp_sa <- azp(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 20,
  method = "sa",
  cooling_rate = 0.85,
  max_iterations = 100,
  seed = 1983
)
```

## SPENC: Spatially-Encouraged Spectral Clustering

*SPENC* [@wolf2021] combines spectral clustering with spatial constraints. It uses a radial basis function (RBF) kernel to measure attribute similarity and incorporates spatial connectivity into the spectral embedding. This approach can find clusters with complex, non-convex shapes that other methods might miss.

```{r}
spenc_result <- spenc(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 15,
  gamma = 1.0,
  seed = 1983
)

maplibre_view(spenc_result, column = ".region", legend = FALSE)
```

The `gamma` parameter controls the RBF kernel bandwidth - higher values create "tighter" clusters in attribute space.

## Ward spatial clustering

Spatially-constrained *Ward* clustering is a hierarchical method that only allows merging adjacent clusters. At each step, it merges the pair of adjacent clusters that minimizes the increase in total within-cluster variance.

```{r}
ward_result <- ward_spatial(
  dallas,
  attrs = c("incomeE", "bachelorsE"),
  n_regions = 15
)

maplibre_view(ward_result, column = ".region", legend = FALSE)
```

Ward clustering is deterministic (no random seed needed) and tends to produce compact, roughly equal-sized regions.

## Choosing an algorithm

Each regionalization algorithm has strengths for different scenarios:

| Algorithm | Best for | Key features |
|----|----|----|
| **Max-P** | Population thresholds | Maximizes number of regions meeting constraints |
| **SKATER** | Fast, interpretable results | Tree-based, good for large datasets |
| **AZP** | High-quality solutions | Multiple optimization variants |
| **SPENC** | Complex cluster shapes | Spectral embedding with spatial constraints |
| **Ward** | Deterministic, balanced regions | Hierarchical, no tuning required |

For most applications, I'd recommend starting with **Max-P** if you have population constraints, or **SKATER** for a quick first pass. If you want to explore the solution space more thoroughly, try **AZP** with tabu search or simulated annealing.

## Next steps

-   [Facility Location](facility-location.html) - Solve location-allocation problems
-   [Huff Model](huff-model.html) - Model market share and retail competition
-   [Travel-Time Cost Matrices](travel-time-matrices.html) - Use real-world travel times

## References

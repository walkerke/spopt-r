[{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to spopt","title":"Contributing to spopt","text":"Thank interest contributing spopt! document provides instructions setting development environment building package source.","code":""},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"installation-for-users","dir":"","previous_headings":"","what":"Installation for users","title":"Contributing to spopt","text":"users install pre-built binaries r-universe: instructions contributors developers need build source.","code":"install.packages(\"spopt\", repos = \"https://walkerke.r-universe.dev\")"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"building-from-source","dir":"","previous_headings":"","what":"Building from source","title":"Contributing to spopt","text":"spopt uses Rust backend via extendr HiGHS solver mixed-integer programming. Building source requires several system dependencies.","code":""},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"macos","dir":"","previous_headings":"Building from source","what":"macOS","title":"Contributing to spopt","text":"Install Rust (already installed): Install system dependencies via Homebrew: Install package:","code":"curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env brew install cmake llvm # install.packages(\"pak\") pak::pak(\"walkerke/spopt-r\")"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"linux-ubuntudebian","dir":"","previous_headings":"Building from source","what":"Linux (Ubuntu/Debian)","title":"Contributing to spopt","text":"Install Rust: Install system dependencies: Install package:","code":"curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env sudo apt-get update sudo apt-get install -y cmake libclang-dev pak::pak(\"walkerke/spopt-r\")"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"windows","dir":"","previous_headings":"Building from source","what":"Windows","title":"Contributing to spopt","text":"Windows builds complex due toolchain requirements. strongly recommend using r-universe binaries Windows. must build source: Install Rtools44 (appropriate version R): Download https://cran.r-project.org/bin/windows/Rtools/ Install Rust using rustup: Download https://rustup.rs/ installation, select x86_64-pc-windows-gnu toolchain Configure Rust GNU toolchain: Install additional MSYS2 packages (Rtools terminal): Install package:","code":"rustup default stable-x86_64-pc-windows-gnu pacman -S mingw-w64-x86_64-cmake mingw-w64-x86_64-clang pak::pak(\"walkerke/spopt-r\")"},{"path":[]},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"making-changes-to-r-code","dir":"","previous_headings":"Development workflow","what":"Making changes to R code","title":"Contributing to spopt","text":"modifying R code R/, regenerate documentation:","code":"devtools::document() devtools::check()"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"making-changes-to-rust-code","dir":"","previous_headings":"Development workflow","what":"Making changes to Rust code","title":"Contributing to spopt","text":"Rust source src/rust/. making changes:","code":"# Recompile Rust code and reload rextendr::document()  # Or for a full rebuild devtools::load_all()"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"running-tests","dir":"","previous_headings":"Development workflow","what":"Running tests","title":"Contributing to spopt","text":"","code":"devtools::test()"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"building-the-pkgdown-site","dir":"","previous_headings":"Development workflow","what":"Building the pkgdown site","title":"Contributing to spopt","text":"vignettes use Quarto. build documentation site:","code":"pkgdown::build_site()"},{"path":"https://walker-data.com/spopt/CONTRIBUTING.html","id":"reporting-issues","dir":"","previous_headings":"","what":"Reporting issues","title":"Contributing to spopt","text":"Please report bugs feature requests https://github.com/walkerke/spopt-r/issues. reporting bugs, please include: - operating system version - R version (sessionInfo()) - minimal reproducible example","code":""},{"path":"https://walker-data.com/spopt/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2026 Kyle Walker Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"setting-up-the-problem","dir":"Articles","previous_headings":"","what":"Setting up the problem","title":"Solving facility location problems with spopt","text":"Facility location problems three core components: Demand points: Locations need served (e.g., population centers, customer addresses) Candidate facilities: Potential sites facilities built Cost matrix: Distance travel time demand point candidate facility key distinction: practice, typically many demand points candidate facility sites. example, might need serve 500 Census tracts 25 potential building sites choose . asymmetry makes problem tractable - solver selects limited set candidates rather considering every possible location. Let’s set realistic scenario: want place community health centers serve population Tarrant County. ’ll use Census tract centroids demand points, sample 30 candidate locations across county represent potential facility sites. now 448 demand points (tract centroids) 30 candidate facility locations. setup mirrors real-world planning ’re evaluating shortlist potential sites.","code":"library(spopt) library(tidycensus) library(tidyverse) library(sf) library(mapgl)  # Get tract-level population data tarrant <- get_acs(   geography = \"tract\",   variables = \"B01003_001\",   state = \"TX\",   county = \"Tarrant\",   geometry = TRUE,   year = 2023 ) |>   filter(estimate > 0) |>   rename(population = estimate)  # Demand points: all tract centroids demand_pts <- tarrant |>   st_centroid()  # Candidate facilities: sample 30 locations across the county # In practice, these might be specific parcels, existing buildings, or zoned commercial sites set.seed(1983) n_candidates <- 30  county_boundary <- tarrant |> st_union() candidate_pts <- st_sample(county_boundary, n_candidates) |>   st_as_sf() |>   mutate(id = row_number()) # Visualize the setup maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"demand\",     source = demand_pts,     circle_color = \"steelblue\",     circle_radius = 3,     circle_opacity = 0.5   ) |>   add_circle_layer(     id = \"candidates\",     source = candidate_pts,     circle_color = \"black\",     circle_radius = 6,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"p-median-minimizing-total-distance","dir":"Articles","previous_headings":"","what":"P-Median: Minimizing total distance","title":"Solving facility location problems with spopt","text":"P-Median problem (Hakimi 1964) minimizes total weighted distance demand points assigned facilities. classic efficiency-focused location model - finds locations minimize far people, average, must travel. solver runs quickly 30 candidates - optimization scales number candidate sites, demand points. Let’s visualize results: demand point colored assigned facility, black markers show selected facility locations. solution minimizes total population-weighted distance. can access solution metadata spopt attribute: objective value represents total weighted distance - lower better.","code":"result_pmedian <- p_median(   demand = demand_pts,   facilities = candidate_pts,   n_facilities = 5,   weight_col = \"population\" ) # Get selected facility locations selected <- result_pmedian$facilities |>   filter(.selected) |>    mutate(id = as.character(id))  # Color demand points by their assigned facility demand_colored <- result_pmedian$demand |>   mutate(.facility = as.character(.facility))  # Map the results maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"demand\",     source = demand_colored,     circle_color = match_expr(       column = \".facility\",       values = selected$id,       stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\")     ),     circle_radius = 4,     circle_opacity = 0.7   ) |>   add_circle_layer(     id = \"facilities\",     source = selected,     circle_color = match_expr(       column = \"id\",       values = selected$id,       stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\")     ),     circle_radius = 10,     circle_stroke_color = \"white\",     circle_stroke_width = 2   ) attr(result_pmedian, \"spopt\") $algorithm [1] \"p_median\"  $n_selected [1] 5  $n_facilities [1] 5  $objective [1] 16669528322  $mean_distance [1] 7805.025  $solve_time [1] 0.289197"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"p-center-minimizing-maximum-distance","dir":"Articles","previous_headings":"","what":"P-Center: Minimizing maximum distance","title":"Solving facility location problems with spopt","text":"P-Median optimizes overall accessibility, P-Center problem (Hakimi 1965) focuses equity - minimizes maximum distance demand point must travel. critical emergency services need guarantee everyone within reasonable distance. Notice P-Center solution (red) pushes facilities toward edges county ensure one far away, P-Median (blue) concentrates facilities population densest. Despite , two common facilities selected solutions.","code":"result_pcenter <- p_center(   demand = demand_pts,   facilities = candidate_pts,   n_facilities = 5 )  selected_pcenter <- result_pcenter$facilities |>   filter(.selected)  # Compare to P-Median locations maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"pmedian\",     source = selected,     circle_color = \"#3498db\",     circle_radius = 10,     circle_stroke_color = \"white\",     circle_stroke_width = 2   ) |>   add_circle_layer(     id = \"pcenter\",     source = selected_pcenter,     circle_color = \"#e74c3c\",     circle_radius = 5,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"mclp-maximum-coverage-with-limited-facilities","dir":"Articles","previous_headings":"","what":"MCLP: Maximum coverage with limited facilities","title":"Solving facility location problems with spopt","text":"Maximum Coverage Location Problem (MCLP) (Church ReVelle 1974) maximizes demand covered within service radius can build fixed number facilities. useful budget constraints want cover many people possible. service_radius parameter defines “covered” means - demand point within distance selected facility considered covered. algorithm selects facilities maximize total covered population.","code":"result_mclp <- mclp(   demand = demand_pts,   facilities = candidate_pts,   n_facilities = 5,   service_radius = 5000,  # 5 km   weight_col = \"population\" )  # Calculate coverage covered_pop <- result_mclp$demand |>   filter(.covered) |>   pull(population) |>   sum()  total_pop <- sum(demand_pts$population, na.rm = TRUE)  cat(sprintf(\"Coverage: %s of %s (%.1f%%)\",             format(covered_pop, big.mark = \",\"),             format(total_pop, big.mark = \",\"),             100 * covered_pop / total_pop)) Coverage: 520,623 of 2,135,743 (24.4%)"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"lscp-minimum-facilities-for-full-coverage","dir":"Articles","previous_headings":"","what":"LSCP: Minimum facilities for full coverage","title":"Solving facility location problems with spopt","text":"Location Set Covering Problem (LSCP) (Toregas et al. 1971) asks opposite question MCLP: ’s minimum number facilities needed cover demand within service radius? solver finds 19 facilities example. LSCP particularly useful planning emergency services coverage mandatory - every resident must within certain response time fire station hospital.","code":"result_lscp <- lscp(   demand = demand_pts,   facilities = candidate_pts,   service_radius = 8000  # 8 km )  n_selected <- sum(result_lscp$facilities$.selected) cat(sprintf(\"Minimum facilities needed for full coverage: %d\", n_selected)) Minimum facilities needed for full coverage: 19"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"p-dispersion-spreading-facilities-apart","dir":"Articles","previous_headings":"","what":"P-Dispersion: Spreading facilities apart","title":"Solving facility location problems with spopt","text":"facility location problems assume demand points want close facilities. facilities obnoxious - landfills, prisons, polluting industries communities want far away. P-Dispersion problem (Kuby 1987) maximizes minimum distance facilities. P-Dispersion also useful environmental monitoring networks cell tower placement want sensors spread across region. Notice facilities spread around county’s perimeter interior - maximizing minimum inter-facility distance.","code":"result_pdispersion <- p_dispersion(   facilities = candidate_pts,   n_facilities = 10 )  selected_disp <- result_pdispersion |>   filter(.selected)  maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"facilities\",     source = selected_disp,     circle_color = \"#2ecc71\",     circle_radius = 10,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"cflp-capacitated-facility-location","dir":"Articles","previous_headings":"","what":"CFLP: Capacitated facility location","title":"Solving facility location problems with spopt","text":"Real facilities capacity limits - clinic can see many patients per day, warehouse can store much inventory. Capacitated Facility Location Problem (CFLP) (Daskin 2013; Sridharan 1995) adds capacity constraints allows demand split across multiple facilities. practice, candidate sites often different capacities based lot size, zoning, building constraints. Let’s simulate realistic scenario small, medium, large sites: solver selects facilities together can serve demand minimizing total distance. Notice .utilization shows fraction facility’s capacity used. demand exceeds capacity nearest facility, solver splits demand across multiple facilities: different sites different costs - perhaps due real estate prices, construction costs, lease rates? CFLP can incorporate costs find economically optimal solution. provide facility_cost_col set n_facilities = 0, solver determines optimal number facilities balancing fixed costs (opening facilities) variable costs (transportation distance). key scaling costs appropriately - fixed costs comparable total transportation costs: mode powerful budget planning: instead arbitrarily choosing 5 facilities, let optimization determine cost-minimizing configuration. Real estate prices typically vary spatially - central locations cost peripheral ones. Let’s create realistic scenario costs increase toward county centroid: Let’s visualize costs vary across county: Red sites expensive (central), blue sites cheaper (peripheral). Larger circles indicate higher capacity. Now let’s compare two solutions: one ignoring costs (P-Median) one incorporating real estate costs: Red circles show distance-solution (P-Median), blue circles show cost-aware solution. Notice cost-aware solution may shift toward cheaper peripheral sites, trading accessibility lower real estate costs.","code":"# Create candidates with varying capacities set.seed(1983) candidate_facilities <- candidate_pts |>   mutate(     # Assign site sizes: small (200k), medium (400k), large (800k)     site_type = sample(c(\"small\", \"medium\", \"large\"), n(), replace = TRUE),     capacity = case_when(       site_type == \"small\" ~ 200000,       site_type == \"medium\" ~ 400000,       site_type == \"large\" ~ 800000     )   )  result_cflp <- cflp(   demand = demand_pts,   facilities = candidate_facilities,   n_facilities = 5,   weight_col = \"population\",   capacity_col = \"capacity\" )  # Check which sites were selected and their utilization result_cflp$facilities |>   filter(.selected) |>   st_drop_geometry() |>   select(id, site_type, capacity, .utilization) id site_type capacity .utilization 1  5    medium    4e+05    0.9712625 2  7    medium    4e+05    1.0000000 3 12    medium    4e+05    1.0000000 4 21     large    8e+05    0.6974662 5 27    medium    4e+05    0.9731625 # How many demand points are split? n_split <- sum(result_cflp$demand$.split) cat(sprintf(\"%d of %d demand points are served by multiple facilities\",             n_split, nrow(demand_pts))) 2 of 448 demand points are served by multiple facilities # Add costs based on site size # Scale to be comparable with total transport costs (population * distance) candidate_with_costs <- candidate_facilities |>   mutate(     # Fixed cost to open each facility (scaled to match transport cost units)     fixed_cost = case_when(       site_type == \"small\" ~ 5e8,   # Higher cost per unit capacity       site_type == \"medium\" ~ 8e8,       site_type == \"large\" ~ 1e9     )   )  result_with_costs <- cflp(   demand = demand_pts,   facilities = candidate_with_costs,   n_facilities = 0,  # Let solver determine optimal number   weight_col = \"population\",   capacity_col = \"capacity\",   facility_cost_col = \"fixed_cost\" )  # How many facilities does the cost-optimized solution select? cost_meta <- attr(result_with_costs, \"spopt\") cat(sprintf(\"Optimal number of facilities: %d\\n\", cost_meta$n_selected)) Optimal number of facilities: 9 # Calculate distance from county centroid (proxy for \"centrality\") county_centroid <- st_centroid(county_boundary)  # Compute distances to center dist_to_center <- as.numeric(st_distance(candidate_facilities, county_centroid))  candidate_with_realestate <- candidate_facilities |>   mutate(     dist_to_center = dist_to_center,     # Costs higher near center, lower at periphery     # Normalize to 0-1 range and invert (closer = higher cost)     centrality = 1 - (dist_to_center - min(dist_to_center)) /                      (max(dist_to_center) - min(dist_to_center)),     # Cost ranges from $200-$500 per sqft based on location     cost_per_sqft = 200 + centrality * 300,     sqft = capacity / 10,  # Assume 10 people per sqft capacity     # Scale fixed cost to be comparable with transport costs     fixed_cost = sqft * cost_per_sqft * 50   ) maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"candidates\",     source = candidate_with_realestate,     circle_color = interpolate(       column = \"cost_per_sqft\",       values = c(200, 350, 500),       stops = c(\"#2166ac\", \"#f7f7f7\", \"#b2182b\")     ),     circle_radius = interpolate(       column = \"capacity\",       values = c(200000, 500000, 800000),       stops = c(6, 10, 14)     ),     circle_stroke_color = \"white\",     circle_stroke_width = 1   ) # Solution ignoring costs (just minimize distance) result_no_cost <- p_median(   demand = demand_pts,   facilities = candidate_with_realestate,   n_facilities = 5,   weight_col = \"population\" )  # Solution with real estate costs result_with_realestate <- cflp(   demand = demand_pts,   facilities = candidate_with_realestate,   n_facilities = 5,   weight_col = \"population\",   capacity_col = \"capacity\",   facility_cost_col = \"fixed_cost\" )  # Compare selections selected_no_cost <- result_no_cost$facilities |>   filter(.selected) |>   mutate(method = \"Distance only\")  selected_with_cost <- result_with_realestate$facilities |>   filter(.selected) |>   mutate(method = \"With real estate costs\") # Side-by-side comparison maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"no_cost\",     source = selected_no_cost,     circle_color = \"#e41a1c\",     circle_radius = 12,     circle_stroke_color = \"white\",     circle_stroke_width = 2   ) |>   add_circle_layer(     id = \"with_cost\",     source = selected_with_cost,     circle_color = \"#377eb8\",     circle_radius = 7,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"varying-capacity-limits","dir":"Articles","previous_headings":"","what":"Varying capacity limits","title":"Solving facility location problems with spopt","text":"practice, candidate sites often different capacities based lot size, zoning, building constraints. Let’s simulate realistic scenario small, medium, large sites: solver selects facilities together can serve demand minimizing total distance. Notice .utilization shows fraction facility’s capacity used. demand exceeds capacity nearest facility, solver splits demand across multiple facilities:","code":"# Create candidates with varying capacities set.seed(1983) candidate_facilities <- candidate_pts |>   mutate(     # Assign site sizes: small (200k), medium (400k), large (800k)     site_type = sample(c(\"small\", \"medium\", \"large\"), n(), replace = TRUE),     capacity = case_when(       site_type == \"small\" ~ 200000,       site_type == \"medium\" ~ 400000,       site_type == \"large\" ~ 800000     )   )  result_cflp <- cflp(   demand = demand_pts,   facilities = candidate_facilities,   n_facilities = 5,   weight_col = \"population\",   capacity_col = \"capacity\" )  # Check which sites were selected and their utilization result_cflp$facilities |>   filter(.selected) |>   st_drop_geometry() |>   select(id, site_type, capacity, .utilization) id site_type capacity .utilization 1  5    medium    4e+05    0.9712625 2  7    medium    4e+05    1.0000000 3 12    medium    4e+05    1.0000000 4 21     large    8e+05    0.6974662 5 27    medium    4e+05    0.9731625 # How many demand points are split? n_split <- sum(result_cflp$demand$.split) cat(sprintf(\"%d of %d demand points are served by multiple facilities\",             n_split, nrow(demand_pts))) 2 of 448 demand points are served by multiple facilities"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"incorporating-facility-costs","dir":"Articles","previous_headings":"","what":"Incorporating facility costs","title":"Solving facility location problems with spopt","text":"different sites different costs - perhaps due real estate prices, construction costs, lease rates? CFLP can incorporate costs find economically optimal solution. provide facility_cost_col set n_facilities = 0, solver determines optimal number facilities balancing fixed costs (opening facilities) variable costs (transportation distance). key scaling costs appropriately - fixed costs comparable total transportation costs: mode powerful budget planning: instead arbitrarily choosing 5 facilities, let optimization determine cost-minimizing configuration.","code":"# Add costs based on site size # Scale to be comparable with total transport costs (population * distance) candidate_with_costs <- candidate_facilities |>   mutate(     # Fixed cost to open each facility (scaled to match transport cost units)     fixed_cost = case_when(       site_type == \"small\" ~ 5e8,   # Higher cost per unit capacity       site_type == \"medium\" ~ 8e8,       site_type == \"large\" ~ 1e9     )   )  result_with_costs <- cflp(   demand = demand_pts,   facilities = candidate_with_costs,   n_facilities = 0,  # Let solver determine optimal number   weight_col = \"population\",   capacity_col = \"capacity\",   facility_cost_col = \"fixed_cost\" )  # How many facilities does the cost-optimized solution select? cost_meta <- attr(result_with_costs, \"spopt\") cat(sprintf(\"Optimal number of facilities: %d\\n\", cost_meta$n_selected)) Optimal number of facilities: 9"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"real-estate-costs-example","dir":"Articles","previous_headings":"","what":"Real estate costs example","title":"Solving facility location problems with spopt","text":"Real estate prices typically vary spatially - central locations cost peripheral ones. Let’s create realistic scenario costs increase toward county centroid: Let’s visualize costs vary across county: Red sites expensive (central), blue sites cheaper (peripheral). Larger circles indicate higher capacity. Now let’s compare two solutions: one ignoring costs (P-Median) one incorporating real estate costs: Red circles show distance-solution (P-Median), blue circles show cost-aware solution. Notice cost-aware solution may shift toward cheaper peripheral sites, trading accessibility lower real estate costs.","code":"# Calculate distance from county centroid (proxy for \"centrality\") county_centroid <- st_centroid(county_boundary)  # Compute distances to center dist_to_center <- as.numeric(st_distance(candidate_facilities, county_centroid))  candidate_with_realestate <- candidate_facilities |>   mutate(     dist_to_center = dist_to_center,     # Costs higher near center, lower at periphery     # Normalize to 0-1 range and invert (closer = higher cost)     centrality = 1 - (dist_to_center - min(dist_to_center)) /                      (max(dist_to_center) - min(dist_to_center)),     # Cost ranges from $200-$500 per sqft based on location     cost_per_sqft = 200 + centrality * 300,     sqft = capacity / 10,  # Assume 10 people per sqft capacity     # Scale fixed cost to be comparable with transport costs     fixed_cost = sqft * cost_per_sqft * 50   ) maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"candidates\",     source = candidate_with_realestate,     circle_color = interpolate(       column = \"cost_per_sqft\",       values = c(200, 350, 500),       stops = c(\"#2166ac\", \"#f7f7f7\", \"#b2182b\")     ),     circle_radius = interpolate(       column = \"capacity\",       values = c(200000, 500000, 800000),       stops = c(6, 10, 14)     ),     circle_stroke_color = \"white\",     circle_stroke_width = 1   ) # Solution ignoring costs (just minimize distance) result_no_cost <- p_median(   demand = demand_pts,   facilities = candidate_with_realestate,   n_facilities = 5,   weight_col = \"population\" )  # Solution with real estate costs result_with_realestate <- cflp(   demand = demand_pts,   facilities = candidate_with_realestate,   n_facilities = 5,   weight_col = \"population\",   capacity_col = \"capacity\",   facility_cost_col = \"fixed_cost\" )  # Compare selections selected_no_cost <- result_no_cost$facilities |>   filter(.selected) |>   mutate(method = \"Distance only\")  selected_with_cost <- result_with_realestate$facilities |>   filter(.selected) |>   mutate(method = \"With real estate costs\") # Side-by-side comparison maplibre(bounds = tarrant) |>   add_fill_layer(     id = \"tracts\",     source = tarrant,     fill_color = \"lightgray\",     fill_opacity = 0.3   ) |>   add_circle_layer(     id = \"no_cost\",     source = selected_no_cost,     circle_color = \"#e41a1c\",     circle_radius = 12,     circle_stroke_color = \"white\",     circle_stroke_width = 2   ) |>   add_circle_layer(     id = \"with_cost\",     source = selected_with_cost,     circle_color = \"#377eb8\",     circle_radius = 7,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"comparing-algorithms","dir":"Articles","previous_headings":"","what":"Comparing algorithms","title":"Solving facility location problems with spopt","text":"’s quick reference choosing right algorithm: public service planning, start P-Median efficiency baseline, compare P-Center see equity trade-offs. hard budget constraint, MCLP helps understand coverage achievable limited facilities.","code":""},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"candidate-site-selection-strategies","dir":"Articles","previous_headings":"","what":"Candidate site selection strategies","title":"Solving facility location problems with spopt","text":"examples used randomly sampled candidate locations. practice, ’d generate candidates thoughtfully: Existing infrastructure: Current facility locations expanded Zoning-based: Sites zoned commercial institutional use Network nodes: Major intersections highway interchanges Population centers: Centroids high-density areas Grid sampling: Regular grid across study area exploratory analysis can also combine strategies - start coarse grid candidates initial analysis, refine specific parcels detailed planning.","code":""},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"using-custom-cost-matrices","dir":"Articles","previous_headings":"","what":"Using custom cost matrices","title":"Solving facility location problems with spopt","text":"default, spopt calculates Euclidean distances points. real-world accessibility depends road networks travel times, straight-line distance. facility location functions accept cost_matrix parameter custom distances. See Travel-Time Cost Matrices vignette generate travel time matrices using r5r, pass functions.","code":"# Example with custom cost matrix cost_mat <- my_travel_time_matrix  # Generated from r5r or similar  result <- p_median(   demand = demand_pts,   facilities = candidate_pts,   n_facilities = 5,   weight_col = \"population\",   cost_matrix = cost_mat )"},{"path":"https://walker-data.com/spopt/articles/facility-location.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Solving facility location problems with spopt","text":"Regionalization - Build spatially-contiguous regions Huff Model - Model market share retail competition Travel-Time Cost Matrices - Use real-world travel times r5r","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/articles/getting-started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting started with spopt","text":"easiest way install spopt r-universe repository, provides pre-built binaries: installed, load package along sf spatial data handling tidyverse data manipulation:","code":"install.packages(\"spopt\", repos = \"https://walkerke.r-universe.dev\") library(spopt) library(sf) library(tidyverse)"},{"path":"https://walker-data.com/spopt/articles/getting-started.html","id":"what-can-spopt-do","dir":"Articles","previous_headings":"","what":"What can spopt do?","title":"Getting started with spopt","text":"spopt includes three families spatial optimization algorithms: Regionalization: Build spatially-contiguous regions smaller geographies. useful need aggregate Census blocks larger areas, create balanced sales territories, design compact political districts. Algorithms include SKATER, AZP, Max-P, SPENC, spatially-constrained Ward clustering. Facility location: Find optimal locations facilities given demand points candidate sites. Whether ’re siting fire stations minimize response times, placing retail stores maximize coverage, locating EV charging stations along highway corridors, spopt algorithms problems. Options include P-Median, P-Center, MCLP, LSCP, CFLP, P-Dispersion, FRLM. Market analysis: Model consumer behavior market competition Huff model. classic retail gravity model predicts market share expected sales based store attractiveness distance consumers.","code":""},{"path":"https://walker-data.com/spopt/articles/getting-started.html","id":"a-quick-example","dir":"Articles","previous_headings":"","what":"A quick example","title":"Getting started with spopt","text":"Let’s run quick facility location analysis see spopt action. ’ll find optimal locations 5 facilities serve Census tracts Tarrant County, Texas (home Fort Worth). p_median() function returns list allocated demand points selected facilities. demand point assigned nearest selected facility, solution minimizes total population-weighted distance.","code":"library(tidycensus)  # Get population data for Tarrant County tracts tarrant <- get_acs(   geography = \"tract\",   variables = \"B01003_001\",   state = \"TX\",   county = \"Tarrant\",   geometry = TRUE,   year = 2023 )  # Use tract centroids as both demand points and candidate facility sites tarrant_pts <- tarrant |>   st_centroid() |>   filter(!is.na(estimate))  # Solve the P-Median problem: minimize total weighted distance result <- p_median(   demand = tarrant_pts,   facilities = tarrant_pts,   n_facilities = 5,   weight_col = \"estimate\" )  # View selected facility locations result$facilities |> filter(.selected) Simple feature collection with 5 features and 7 fields Geometry type: POINT Dimension:     XY Bounding box:  xmin: -97.40206 ymin: 32.66538 xmax: -97.12351 ymax: 32.89751 Geodetic CRS:  NAD83         GEOID                                        NAME   variable estimate 1 48439111516 Census Tract 1115.16; Tarrant County; Texas B01003_001     7137 2 48439113637 Census Tract 1136.37; Tarrant County; Texas B01003_001     4732 3 48439110402 Census Tract 1104.02; Tarrant County; Texas B01003_001     5387 4 48439105800    Census Tract 1058; Tarrant County; Texas B01003_001     4430 5 48439113946 Census Tract 1139.46; Tarrant County; Texas B01003_001     6509    moe                   geometry .selected .n_assigned 1 1007 POINT (-97.12453 32.66618)      TRUE         112 2  703 POINT (-97.12351 32.84844)      TRUE          90 3   16 POINT (-97.40206 32.80275)      TRUE          69 4  698 POINT (-97.34284 32.66538)      TRUE         107 5 3880 POINT (-97.28117 32.89751)      TRUE          71"},{"path":"https://walker-data.com/spopt/articles/getting-started.html","id":"sf-first-design","dir":"Articles","previous_headings":"","what":"SF-first design","title":"Getting started with spopt","text":"spopt functions accept return sf objects. means can: Pass sf polygons points directly functions Use coordinate reference system (functions handle transformations internally) Pipe results directly visualization ggplot2, mapview, mapgl Integrate seamlessly tidycensus, tigris, spatial R packages","code":""},{"path":"https://walker-data.com/spopt/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting started with spopt","text":"Regionalization - Build spatially-contiguous regions SKATER, AZP, Max-P, Facility Location - Solve location-allocation problems P-Median, MCLP, algorithms Huff Model - Model market share retail competition Travel-Time Cost Matrices - Use real-world travel times r5r routing engines","code":""},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"the-huff-model-formula","dir":"Articles","previous_headings":"","what":"The Huff model formula","title":"Market analysis with the Huff model","text":"probability consumer location ii visit store jj : Pij=Ajα⋅Dijβ∑k=1nAkα⋅DikβP_{ij} = \\frac{A_j^\\alpha \\cdot D_{ij}^\\beta}{\\sum_{k=1}^{n} A_k^\\alpha \\cdot D_{ik}^\\beta} : AjA_j attractiveness store jj (e.g., square footage) DijD_{ij} distance consumer ii store jj α\\alpha attractiveness exponent (typically positive) β\\beta distance decay exponent (typically negative) model assumes consumers trade attractiveness distance - larger store might attract customers farther away, consumers also prefer closer stores, else equal.","code":""},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"setting-up-the-analysis","dir":"Articles","previous_headings":"","what":"Setting up the analysis","title":"Market analysis with the Huff model","text":"Let’s analyze grocery store competition Austin metro area. ’ll use Census block group data represent consumer demand locations, set real store locations. ’ve created “spending potential” variable combines population income - block groups higher incomes spending potential per capita. serve demand weight. Now let’s define store locations. example, ’ll create simulated set HEB Whole Foods locations Austin area:","code":"library(spopt) library(tidycensus) library(tidyverse) library(sf) library(mapgl)  # Get block group data for Travis, Williamson, and Hays counties austin_counties <- c(\"Travis\", \"Williamson\", \"Hays\")  demand <- get_acs(   geography = \"block group\",   variables = c(pop = \"B01003_001\", income = \"B19013_001\"),   state = \"TX\",   county = austin_counties,   geometry = TRUE,   year = 2023,   output = \"wide\" ) |>   st_transform(4326) |>   filter(!is.na(incomeE)) |>   mutate(     # Spending potential: population weighted by relative income     spending = popE * (incomeE / median(incomeE, na.rm = TRUE))   ) stores <- tibble(   id = paste0(\"Store_\", 1:8),   name = c(     \"HEB Mueller\", \"HEB Tech Ridge\", \"HEB Hancock\", \"HEB South Congress\",     \"Whole Foods Downtown\", \"Whole Foods Domain\", \"HEB Round Rock\", \"HEB Cedar Park\"   ),   chain = c(rep(\"HEB\", 4), rep(\"Whole Foods\", 2), rep(\"HEB\", 2)),   sqft = c(80000, 75000, 55000, 70000, 40000, 35000, 85000, 72000),   lon = c(-97.7025, -97.6920, -97.7215, -97.7830,           -97.7495, -97.7235, -97.6790, -97.8200),   lat = c(30.2950, 30.4420, 30.3030, 30.2280,           30.2690, 30.4020, 30.5080, 30.5100) ) |>   st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"running-the-huff-model","dir":"Articles","previous_headings":"","what":"Running the Huff model","title":"Market analysis with the Huff model","text":"huff() function calculates market probabilities expected sales store. need provide: demand: Consumer locations - can polygons (like block groups) points. polygons, distances computed centroids automatically. stores: Store locations attractiveness data attractiveness_col: column measuring store attractiveness distance_exponent: Controls quickly distance reduces attractiveness (negative values) function returns list two sf objects include results: .primary_store: ID highest-probability store location .entropy: Competition measure (higher = competition stores) .prob_<store_id>: Probability column store .market_share: Proportion total market captured .expected_sales: Expected sales (sum probability × sales potential)","code":"result <- huff(   demand = demand,   stores = stores,   attractiveness_col = \"sqft\",   attractiveness_exponent = 1.0,   distance_exponent = -1.5,   sales_potential_col = \"spending\" )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"visualizing-market-areas","dir":"Articles","previous_headings":"","what":"Visualizing market areas","title":"Market analysis with the Huff model","text":"Let’s map primary store block group - store highest probability visited. Since result$demand already sf object .primary_store included, can map directly: map shows block group colored primary store. gives us quick sense store’s trade area - geographic region draws customers. Note assignments exclusive function distance; probabilities also influenced store size, using attractiveness metric. real-world example, retail metrics (traffic counts, foot traffic, etc.) might used .","code":"maplibre(bounds = result$demand) |>   add_fill_layer(     id = \"market_areas\",     source = result$demand,     fill_color = match_expr(       column = \".primary_store\",       values = 1:8,       stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\",                 \"#ff7f00\", \"#a65628\", \"#f781bf\", \"#999999\")     ),     fill_opacity = 0.6   ) |>   add_line_layer(     id = \"borders\",     source = result$demand,     line_color = \"white\",     line_width = 0.3   ) |>   add_circle_layer(     id = \"stores\",     source = result$stores,     circle_color = \"black\",     circle_radius = 8,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"understanding-market-share","dir":"Articles","previous_headings":"","what":"Understanding market share","title":"Market analysis with the Huff model","text":"stores result contains market share expected sales location: market share column (.market_share) shows store’s share total expected sales across study area. Larger stores less competitive areas tend capture market share.","code":"result$stores |>   st_drop_geometry() |>   select(name, chain, sqft, .expected_sales, .market_share) |>   arrange(desc(.market_share)) # A tibble: 8 × 5   name                 chain        sqft .expected_sales .market_share   <chr>                <chr>       <dbl>           <dbl>         <dbl> 1 HEB Round Rock       HEB         85000         397953.        0.168 2 HEB Cedar Park       HEB         72000         358571.        0.151 3 HEB South Congress   HEB         70000         353076.        0.149 4 HEB Tech Ridge       HEB         75000         335597.        0.142 5 HEB Mueller          HEB         80000         328209.        0.139 6 HEB Hancock          HEB         55000         234390.        0.0990 7 Whole Foods Downtown Whole Foods 40000         194714.        0.0822 8 Whole Foods Domain   Whole Foods 35000         165036.        0.0697"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"competition-and-entropy","dir":"Articles","previous_headings":"","what":"Competition and entropy","title":"Market analysis with the Huff model","text":"Huff model also calculates entropy demand location - measure competition intensity. Entropy high consumers multiple similarly-attractive options, low one store dominates. included directly result$demand: Areas high entropy (red) intense competition - consumers multiple good options. Low-entropy areas (blue) dominated single store; often areas immediately adjacent store location.","code":"maplibre(bounds = result$demand) |>   add_fill_layer(     id = \"entropy\",     source = result$demand,     fill_color = interpolate(       column = \".entropy\",       values = c(0, 1.5, 2),       stops = c(\"#2166ac\", \"#f7f7f7\", \"#b2182b\")     ),     fill_opacity = 0.7,     tooltip = \".entropy\"   ) |>   add_circle_layer(     id = \"stores\",     source = result$stores,     circle_color = \"black\",     circle_radius = 8,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"evaluating-new-store-locations","dir":"Articles","previous_headings":"","what":"Evaluating new store locations","title":"Market analysis with the Huff model","text":"One powerful applications Huff model -analysis - evaluating new store affect market share. Let’s test potential new location south Austin: analysis shows new store cannibalize sales existing locations. Stores near new location see market share decline, distant stores affected. Let’s visualize new store reshapes market areas: Compare original market area map - new store (teal) carves trade area south Austin, primarily expense nearby HEB South Congress location.","code":"# Add a hypothetical new store new_store <- tibble(   id = \"Store_9\",   name = \"New HEB South Austin\",   chain = \"HEB\",   sqft = 70000,   lon = -97.78,   lat = 30.20 ) |>   st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)  stores_with_new <- bind_rows(stores, new_store)  # Re-run the model result_new <- huff(   demand = demand,   stores = stores_with_new,   attractiveness_col = \"sqft\",   attractiveness_exponent = 1.0,   distance_exponent = -1.5,   sales_potential_col = \"spending\" )  # Compare market shares comparison <- result$stores |>   st_drop_geometry() |>   select(name, original_share = .market_share) |>   left_join(     result_new$stores |>       st_drop_geometry() |>       select(name, new_share = .market_share),     by = \"name\"   ) |>   mutate(change = new_share - original_share)  comparison # A tibble: 8 × 4   name                 original_share new_share   change   <chr>                         <dbl>     <dbl>    <dbl> 1 HEB Mueller                  0.139     0.121  -0.0176 2 HEB Tech Ridge               0.142     0.131  -0.0105 3 HEB Hancock                  0.0990    0.0865 -0.0125 4 HEB South Congress           0.149     0.114  -0.0349 5 Whole Foods Downtown         0.0822    0.0697 -0.0125 6 Whole Foods Domain           0.0697    0.0639 -0.00585 7 HEB Round Rock               0.168     0.158  -0.0105 8 HEB Cedar Park               0.151     0.141  -0.01000 maplibre(bounds = result_new$demand) |>   add_fill_layer(     id = \"market_areas\",     source = result_new$demand,     fill_color = match_expr(       column = \".primary_store\",       values = 1:9,       stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\",                 \"#ff7f00\", \"#a65628\", \"#f781bf\", \"#999999\", \"#66c2a5\")     ),     fill_opacity = 0.6   ) |>   add_line_layer(     id = \"borders\",     source = result_new$demand,     line_color = \"white\",     line_width = 0.3   ) |>   add_circle_layer(     id = \"stores\",     source = result_new$stores,     circle_color = \"black\",     circle_radius = 8,     circle_stroke_color = \"white\",     circle_stroke_width = 2   )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"adjusting-model-parameters","dir":"Articles","previous_headings":"","what":"Adjusting model parameters","title":"Market analysis with the Huff model","text":"distance_exponent attractiveness_exponent parameters significantly affect results: Distance exponent (typically -0.5 -3.0): Values closer 0: Consumers willing travel far attractive stores negative values: Strong preference nearby stores Attractiveness exponent (typically 0.5 2.0): Values near 1: Linear relationship size attractiveness Values > 1: Larger stores disproportionately attractive Values < 1: Diminishing returns size steeper distance decay (-2.5 vs -1.5), trade areas become smaller localized. might realistic convenience-oriented shopping consumers prioritize proximity.","code":"# Test with stronger distance decay result_steep <- huff(   demand = demand,   stores = stores,   attractiveness_col = \"sqft\",   attractiveness_exponent = 1.0,   distance_exponent = -2.5,  # Much steeper decay   sales_potential_col = \"spending\" )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"using-composite-attractiveness","dir":"Articles","previous_headings":"","what":"Using composite attractiveness","title":"Market analysis with the Huff model","text":"Store attractiveness isn’t always just size. might want combine multiple factors - size, brand perception, parking availability, product selection. spopt supports multiple attractiveness variables directly: composite attractiveness computed Aj=sqft1.0×parking0.5A_j = \\text{sqft}^{1.0} \\times \\text{parking}^{0.5}. can also pre-compute single attractiveness column prefer:","code":"# Add parking data to stores stores_extended <- stores |>   mutate(parking = c(300, 250, 150, 200, 120, 100, 350, 275))  # Use both sqft and parking as attractiveness factors result_multi <- huff(   demand = demand,   stores = stores_extended,   attractiveness_col = c(\"sqft\", \"parking\"),   attractiveness_exponent = c(1.0, 0.5),  # parking has diminishing returns   distance_exponent = -1.5,   sales_potential_col = \"spending\" ) stores_composite <- stores |>   mutate(     # HEB stores get a 20% brand premium     brand_factor = if_else(chain == \"HEB\", 1.2, 1.0),     attractiveness = sqft * brand_factor   )  result_composite <- huff(   demand = demand,   stores = stores_composite,   attractiveness_col = \"attractiveness\",   distance_exponent = -1.5,   sales_potential_col = \"spending\" )"},{"path":"https://walker-data.com/spopt/articles/huff-model.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Market analysis with the Huff model","text":"Facility Location - Optimize facility placement Regionalization - Build custom regions Census data Travel-Time Cost Matrices - Use driving times instead straight-line distances","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"when-would-you-use-regionalization","dir":"Articles","previous_headings":"","what":"When would you use regionalization?","title":"Regionalization with spopt","text":"Regionalization solves problems across many fields: Political redistricting: Building compact, contiguous districts balance population Market segmentation: Creating sales territories similar customer characteristics Health planning: Aggregating small-area data preserving spatial relationships Urban planning: Delineating neighborhoods based socioeconomic similarity Census data analysis: Addressing differential privacy concerns aggregating blocks larger areas","code":""},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"getting-census-data","dir":"Articles","previous_headings":"","what":"Getting Census data","title":"Regionalization with spopt","text":"Let’s start pulling demographic data Census tracts Dallas County, Texas. ’ll use tidycensus package get population, median household income, percentage bachelor’s degree - variables might define meaningful neighborhood clusters. now 642 Census tracts population, income, education data. Let’s take quick look geographic distribution median household income: map reveals familiar spatial pattern income inequality Dallas - higher incomes concentrated Park Cities north downtown, lower incomes southern part county.","code":"library(spopt) library(tidycensus) library(tidyverse) library(sf) library(mapgl)  dallas <- get_acs(   geography = \"tract\",   variables = c(     pop = \"B01003_001\",     income = \"B19013_001\",     bachelors = \"DP02_0068P\"   ),   state = \"TX\",   county = \"Dallas\",   geometry = TRUE,   year = 2023,   output = \"wide\" ) |>   filter(!is.na(incomeE), !is.na(bachelorsE)) maplibre_view(dallas, column = \"incomeE\")"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"max-p-regionalization","dir":"Articles","previous_headings":"","what":"Max-P regionalization","title":"Regionalization with spopt","text":"Max-P algorithm (Duque, Anselin, Rey 2012) finds maximum number regions region exceeds specified threshold minimizing within-region heterogeneity. particularly useful need regions meet minimum population requirements statistical reliability. Recent extensions support compactness constraints (Feng, Rey, Wei 2022) improved efficiency (Wei, Rey, Knaap 2021). Let’s create regions must contain least 50,000 people: Let’s step key parameters: attrs: variables used measure similarity. Tracts similar income education levels grouped together. threshold_var: variable must meet minimum threshold (population case). threshold: region must least many people. n_iterations: algorithm uses tabu search heuristic; iterations generally yield better solutions. seed: reproducibility, since algorithm stochastic elements. result sf object new .region column indicating tract’s assigned region. algorithm found 41 regions, least 50,000 residents. can access metadata solution spopt attribute: default, regionalization functions use queen contiguity - two tracts neighbors share boundary point (including corners). can also use rook contiguity, tracts must share edge neighbors: control, can specify weights list: list(type = \"knn\", k = 6): K-nearest neighbors (useful point data ensuring connectivity) list(type = \"distance\", d = 5000): Distance-based weights (units match CRS) can also pass nb object created spdep spopt’s sp_weights() function. applications like sales territories electoral districts, may want regions compact, regular shapes. compact parameter optimizes compactness addition attribute homogeneity: compact_weight parameter (0 1) controls trade-attribute homogeneity geometric compactness. Higher values prioritize compact shapes.","code":"maxp_result <- max_p_regions(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   threshold_var = \"popE\",   threshold = 50000,   n_iterations = 100,   seed = 1983 )  maplibre_view(maxp_result, column = \".region\", legend = FALSE) attr(maxp_result, \"spopt\") $algorithm [1] \"max_p\"  $n_regions [1] 41  $objective [1] 590.8766  $threshold_var [1] \"popE\"  $threshold [1] 50000  $region_stats    region n_areas threshold_sum meets_threshold 1      32      21         72029            TRUE 2       3      15         53946            TRUE 3      23      21         63065            TRUE 4      30      17         62150            TRUE 5      24      26         71536            TRUE 6      37      21         83805            TRUE 7      38      18         50354            TRUE 8      29      15         66966            TRUE 9      35      15         56258            TRUE 10     16      11         53648            TRUE 11      1      14         56269            TRUE 12      8      18         52794            TRUE 13     28      15         55143            TRUE 14     22      15         57214            TRUE 15     19      13         54953            TRUE 16      9      13         57807            TRUE 17     27      13         59039            TRUE 18     12      15         76933            TRUE 19      2      12         75397            TRUE 20      7      14         56740            TRUE 21      6      16         61365            TRUE 22     20      12         55996            TRUE 23     39      15         54040            TRUE 24     25      13         56181            TRUE 25     36      15         66457            TRUE 26     21      12         59392            TRUE 27     40      16         59179            TRUE 28     31      24        102478            TRUE 29     34      19         61859            TRUE 30     17      19         61110            TRUE 31     14      18         71146            TRUE 32     26      13         56329            TRUE 33     10      14         62108            TRUE 34     15      14         54934            TRUE 35      4      13         71990            TRUE 36      5      18         75197            TRUE 37     13      14         70617            TRUE 38     41      12         64772            TRUE 39     11      12         54340            TRUE 40     33      18         78145            TRUE 41     18      13         65175            TRUE  $solve_time [1] 0.06877184  $scaled [1] TRUE  $n_iterations [1] 100  $n_sa_iterations [1] 100  $compact [1] FALSE  $compact_weight [1] 0.5  $mean_compactness NULL  $region_compactness NULL maxp_rook <- max_p_regions(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   threshold_var = \"popE\",   threshold = 50000,   weights = \"rook\",   n_iterations = 100,   seed = 1983 ) maxp_compact <- max_p_regions(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   threshold_var = \"popE\",   threshold = 50000,   weights = \"rook\",   compact = TRUE,   compact_weight = 0.5,   n_iterations = 100,   seed = 1983 )  maplibre_view(maxp_compact, column = \".region\", legend = FALSE)"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"spatial-weights","dir":"Articles","previous_headings":"","what":"Spatial weights","title":"Regionalization with spopt","text":"default, regionalization functions use queen contiguity - two tracts neighbors share boundary point (including corners). can also use rook contiguity, tracts must share edge neighbors: control, can specify weights list: list(type = \"knn\", k = 6): K-nearest neighbors (useful point data ensuring connectivity) list(type = \"distance\", d = 5000): Distance-based weights (units match CRS) can also pass nb object created spdep spopt’s sp_weights() function.","code":"maxp_rook <- max_p_regions(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   threshold_var = \"popE\",   threshold = 50000,   weights = \"rook\",   n_iterations = 100,   seed = 1983 )"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"compact-regions","dir":"Articles","previous_headings":"","what":"Compact regions","title":"Regionalization with spopt","text":"applications like sales territories electoral districts, may want regions compact, regular shapes. compact parameter optimizes compactness addition attribute homogeneity: compact_weight parameter (0 1) controls trade-attribute homogeneity geometric compactness. Higher values prioritize compact shapes.","code":"maxp_compact <- max_p_regions(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   threshold_var = \"popE\",   threshold = 50000,   weights = \"rook\",   compact = TRUE,   compact_weight = 0.5,   n_iterations = 100,   seed = 1983 )  maplibre_view(maxp_compact, column = \".region\", legend = FALSE)"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"skater-algorithm","dir":"Articles","previous_headings":"","what":"SKATER algorithm","title":"Regionalization with spopt","text":"SKATER (Spatial K’luster Analysis Tree Edge Removal) (Assunção et al. 2006) takes different approach. first builds minimum spanning tree connecting tracts based attribute similarity, iteratively removes edges create clusters. algorithm fast produces spatially coherent regions. SKATER supports floor floor_value parameter need minimum population constraints:","code":"skater_result <- skater(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 6,   seed = 1983 )  maplibre_view(skater_result, column = \".region\", legend = FALSE) skater_constrained <- skater(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 6,   floor = \"popE\",   floor_value = 150000,   seed = 1983 )"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"azp-automatic-zoning-procedure","dir":"Articles","previous_headings":"","what":"AZP: Automatic Zoning Procedure","title":"Regionalization with spopt","text":"Automatic Zoning Procedure (AZP) (Openshaw 1977; Openshaw Rao 1995) uses local search optimization three algorithm variants: basic (greedy), tabu search, simulated annealing. method parameter controls algorithm variant use: \"basic\": Simple greedy local search (fastest) \"tabu\": Tabu search, maintains list recent moves avoid getting stuck local optima \"sa\": Simulated annealing, accepts worse solutions early explore solution space large problems, may also want use simulated annealing variant:","code":"azp_result <- azp(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 20,   method = \"tabu\",   tabu_length = 10,   max_iterations = 100,   seed = 1983 )  maplibre_view(azp_result, column = \".region\", legend = FALSE) azp_sa <- azp(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 20,   method = \"sa\",   cooling_rate = 0.85,   max_iterations = 100,   seed = 1983 )"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"spenc-spatially-encouraged-spectral-clustering","dir":"Articles","previous_headings":"","what":"SPENC: Spatially-Encouraged Spectral Clustering","title":"Regionalization with spopt","text":"SPENC (Wolf 2021) combines spectral clustering spatial constraints. uses radial basis function (RBF) kernel measure attribute similarity incorporates spatial connectivity spectral embedding. approach can find clusters complex, non-convex shapes methods might miss. gamma parameter controls RBF kernel bandwidth - higher values create “tighter” clusters attribute space.","code":"spenc_result <- spenc(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 15,   gamma = 1.0,   seed = 1983 )  maplibre_view(spenc_result, column = \".region\", legend = FALSE)"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"ward-spatial-clustering","dir":"Articles","previous_headings":"","what":"Ward spatial clustering","title":"Regionalization with spopt","text":"Spatially-constrained Ward clustering hierarchical method allows merging adjacent clusters. step, merges pair adjacent clusters minimizes increase total within-cluster variance. Ward clustering deterministic (random seed needed) tends produce compact, roughly equal-sized regions.","code":"ward_result <- ward_spatial(   dallas,   attrs = c(\"incomeE\", \"bachelorsE\"),   n_regions = 15 )  maplibre_view(ward_result, column = \".region\", legend = FALSE)"},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"choosing-an-algorithm","dir":"Articles","previous_headings":"","what":"Choosing an algorithm","title":"Regionalization with spopt","text":"regionalization algorithm strengths different scenarios: applications, ’d recommend starting Max-P population constraints, SKATER quick first pass. want explore solution space thoroughly, try AZP tabu search simulated annealing.","code":""},{"path":"https://walker-data.com/spopt/articles/regionalization.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Regionalization with spopt","text":"Facility Location - Solve location-allocation problems Huff Model - Model market share retail competition Travel-Time Cost Matrices - Use real-world travel times","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"why-travel-times-matter","dir":"Articles","previous_headings":"","what":"Why travel times matter","title":"Travel-time cost matrices","text":"Consider placing emergency medical services metropolitan area. Straight-line distance might suggest one configuration, accounting actual drive times - influenced road networks, speed limits, traffic - yield different optimal locations. difference can substantial. areas limited river crossings, highway barriers, mountainous terrain, Euclidean distance can significantly underestimate actual travel costs. high-stakes decisions like emergency service placement critical infrastructure siting, using real travel times essential.","code":""},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"routing-options-in-r","dir":"Articles","previous_headings":"","what":"Routing options in R","title":"Travel-time cost matrices","text":"Several R packages can generate travel-time matrices, including limited : r5r: Fast routing using R5 engine; supports driving, walking, cycling, public transit; handles large-scale analyses dodgr: Street network routing using OpenStreetMap data; good walking cycling osrm: Interface OSRM routing engine; fast car routing traffic-like weights mapboxapi: Interface Mapbox’s routing services; includes traffic-aware routing googleway: Interface Google’s Directions API vignette, ’ll use r5r generate travel-time matrix, demonstrate use spopt’s facility location algorithms.","code":""},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"generating-a-travel-time-matrix-with-r5r","dir":"Articles","previous_headings":"","what":"Generating a travel-time matrix with r5r","title":"Travel-time cost matrices","text":"r5r requires Java 21 OpenStreetMap data. ’s workflow used generate travel-time matrix Tarrant County, Texas:","code":"# Install r5r and set up Java install.packages(\"r5r\") install.packages(\"rJavaEnv\") rJavaEnv::java_quick_install(version = 21)  # Set Java memory and load libraries options(java.parameters = \"-Xmx8G\") # Allocating 8GB RAM library(r5r) library(sf) library(tidyverse) library(tidycensus)  # Download and clip OSM data to study area # First, fetch OSM data from https://download.geofabrik.de/north-america/us-south-latest.osm.pbf (3.7GB) # Then, use osmium to clip the US South extract to Tarrant County: # osmium extract -b -97.55,32.55,-97.0,33.05 us-south.osm.pbf -o tarrant.osm.pbf  # Build routing network data_path <- \"path/to/osm/directory\" r5r_core <- build_network(data_path = data_path)  # Get tract centroids as demand points tarrant_tracts <- get_acs(  geography = \"tract\",  variables = \"B01003_001\",  state = \"TX\",  county = \"Tarrant\",  geometry = TRUE,  year = 2023 ) |>  filter(estimate > 0) |>  rename(population = estimate)  demand_pts <- tarrant_tracts |>  st_centroid() |>  st_transform(4326) |>  mutate(id = row_number())  # Sample 30 candidate facility locations set.seed(1983) candidate_pts <- st_sample(st_union(tarrant_tracts), 30) |>  st_as_sf() |>  st_transform(4326) |>  mutate(id = row_number())  # Prepare points for r5r (requires id, lon, lat columns) demand_r5r <- demand_pts |>  st_coordinates() |>  as_tibble() |>  rename(lon = X, lat = Y) |>  mutate(id = as.character(demand_pts$id))  candidates_r5r <- candidate_pts |>  st_coordinates() |>  as_tibble() |>  rename(lon = X, lat = Y) |>  mutate(id = as.character(candidate_pts$id))  # Calculate travel-time matrix ttm <- travel_time_matrix(  r5r_core,  origins = demand_r5r,  destinations = candidates_r5r,  mode = \"CAR\",  departure_datetime = as.POSIXct(\"2025-03-15 08:00:00\"),  max_trip_duration = 120,  progress = TRUE )  # Reshape to matrix format ttm_matrix <- ttm |>  select(from_id, to_id, travel_time_p50) |>  pivot_wider(names_from = to_id, values_from = travel_time_p50) |>  arrange(as.numeric(from_id)) |>  select(-from_id) |>  as.matrix()  ttm_matrix[is.na(ttm_matrix)] <- Inf  stop_r5(r5r_core)"},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"using-the-bundled-travel-time-data","dir":"Articles","previous_headings":"","what":"Using the bundled travel-time data","title":"Travel-time cost matrices","text":"spopt includes pre-computed travel-time matrix Tarrant County ’ll use examples . data generated using workflow . matrix 448 rows (demand points) 30 columns (candidate facilities), travel times minutes.","code":"library(spopt) library(sf) library(tidyverse) library(mapgl)  # Load the bundled data data(tarrant_travel_times)  # Extract components tracts <- tarrant_travel_times$tracts demand <- tarrant_travel_times$demand candidates <- tarrant_travel_times$candidates ttm <- tarrant_travel_times$matrix  # Check dimensions dim(ttm) [1] 448  30"},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"p-median-euclidean-vs-travel-time","dir":"Articles","previous_headings":"","what":"P-Median: Euclidean vs travel time","title":"Travel-time cost matrices","text":"Let’s compare P-Median solutions using Euclidean distance versus actual travel times: two methods select quite different facility locations. Let’s visualize comparison: Purple markers indicate facilities selected methods, red markers selected using travel times, blue markers selected Euclidean distance.","code":"# Solution using travel-time matrix result_tt <- p_median(  demand = demand,  facilities = candidates,  n_facilities = 5,  weight_col = \"population\",  cost_matrix = ttm )  # Solution using Euclidean distance result_euc <- p_median(  demand = demand,  facilities = candidates,  n_facilities = 5,  weight_col = \"population\" )  # Get selected facility IDs from each solution selected_tt_ids <- result_tt$facilities |>  filter(.selected) |>  pull(id)  selected_euc_ids <- result_euc$facilities |>  filter(.selected) |>  pull(id)  # Categorize facilities candidates_compared <- candidates |>  mutate(    selected_tt = id %in% selected_tt_ids,    selected_euc = id %in% selected_euc_ids,    category = case_when(      selected_tt & selected_euc ~ \"Both methods\",      selected_tt ~ \"Travel time only\",      selected_euc ~ \"Euclidean only\",      TRUE ~ \"Not selected\"    )  )  # Count by category candidates_compared |>  st_drop_geometry() |>  filter(category != \"Not selected\") |>  count(category) category n 1     Both methods 1 2   Euclidean only 4 3 Travel time only 4 # Filter to only selected facilities selected_facilities <- candidates_compared |>  filter(category != \"Not selected\")  maplibre(bounds = tracts) |>  add_fill_layer(    id = \"tracts\",    source = tracts,    fill_color = \"lightgray\",    fill_opacity = 0.3  ) |>  add_circle_layer(    id = \"facilities\",    source = selected_facilities,    circle_radius = 10,    circle_color = match_expr(      column = \"category\",      values = c(\"Both methods\", \"Travel time only\", \"Euclidean only\"),      stops = c(\"#9b59b6\", \"#e74c3c\", \"#3498db\")    ),    circle_stroke_color = \"white\",    circle_stroke_width = 2  )"},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"why-the-solutions-differ","dir":"Articles","previous_headings":"","what":"Why the solutions differ","title":"Travel-time cost matrices","text":"travel-time solution accounts actual road network. Facilities shift toward locations better highway access, even ’re farther straight-line distance. Let’s examine objective values: Note objectives use different units (minutes vs meters), ’re directly comparable. matters solution optimal respective cost measure.","code":"# Compare objective values tt_obj <- attr(result_tt, \"spopt\")$objective euc_obj <- attr(result_euc, \"spopt\")$objective  cat(\"Travel-time solution objective:\", round(tt_obj, 0), \"person-minutes\\n\") Travel-time solution objective: 29305339 person-minutes cat(\"Euclidean solution objective:\", round(euc_obj, 0), \"person-meters\\n\") Euclidean solution objective: 16669528322 person-meters"},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"visualizing-service-areas","dir":"Articles","previous_headings":"","what":"Visualizing service areas","title":"Travel-time cost matrices","text":"can also visualize demand points assigned facilities solution: demand point colored assigned facility. Notice service areas follow road network structure rather forming simple circular regions; look particular along major highways.","code":"# Get demand assignments from travel-time solution demand_tt <- result_tt$demand |>  mutate(facility_id = as.character(.facility))  # Get the selected facilities facilities_tt <- result_tt$facilities |>  filter(.selected) |>  mutate(facility_id = as.character(id))  maplibre(bounds = tracts) |>  add_fill_layer(    id = \"tracts\",    source = tracts,    fill_color = \"lightgray\",    fill_opacity = 0.2  ) |>  add_circle_layer(    id = \"demand\",    source = demand_tt,    circle_radius = 4,    circle_opacity = 0.7,    circle_color = match_expr(      column = \"facility_id\",      values = facilities_tt$facility_id,      stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\")    )  ) |>  add_circle_layer(    id = \"facilities\",    source = facilities_tt,    circle_radius = 12,    circle_color = match_expr(      column = \"facility_id\",      values = facilities_tt$facility_id,      stops = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\")    ),    circle_stroke_color = \"white\",    circle_stroke_width = 3  )"},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best practices","title":"Travel-time cost matrices","text":"working travel-time matrices: Match row/column order: Ensure cost matrix rows correspond demand points columns facilities order sf objects. Handle unreachable pairs: Set unreachable origin-destination pairs Inf rather NA. Cache matrices: Travel-time computation expensive. Save matrices readr::write_rds() reuse. Optimize source data: speed matrix calculations, clip OSM source data close possible area analysis osmium building routing network. using third-party API, pay close attention costs. many--many matrices required solving optimization problems, Google / Mapbox APIs can get expensive quickly.","code":""},{"path":"https://walker-data.com/spopt/articles/travel-time-matrices.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Travel-time cost matrices","text":"Facility Location - Overview location algorithms Huff Model - Travel times also work Huff model Regionalization - Build custom regions","code":""},{"path":"https://walker-data.com/spopt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle Walker. Author, maintainer. PySAL Developers. Copyright holder.           Original Python spopt library","code":""},{"path":"https://walker-data.com/spopt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Walker K (2026). spopt: Spatial Optimization Regionalization, Facility Location, Market Analysis. R package version 0.1, https://github.com/kylewalker/spopt-r.","code":"@Manual{,   title = {spopt: Spatial Optimization for Regionalization, Facility Location, and Market Analysis},   author = {Kyle Walker},   year = {2026},   note = {R package version 0.1},   url = {https://github.com/kylewalker/spopt-r}, }"},{"path":"https://walker-data.com/spopt/index.html","id":"spopt-","dir":"","previous_headings":"","what":"spopt","title":"spopt","text":"spopt R package provides R-native implementations spatial optimization algorithms regionalization, facility location, market analysis. Inspired Python’s PySAL spopt, package brings powerful algorithms R users sf-first API Rust backend performance. Install r-universe: developers need build source (requires Rust), see CONTRIBUTING.md. Read vignettes learn use package: Getting started spopt Regionalization Facility location problems Huff model Travel-time cost matrices","code":"install.packages(\"spopt\", repos = \"https://walkerke.r-universe.dev\")"},{"path":"https://walker-data.com/spopt/index.html","id":"support-and-how-to-learn-more","dir":"","previous_headings":"","what":"Support and how to learn more","title":"spopt","text":"find project useful work like ensure continued development package, can provide support following ways: Chip funds support package development via PayPal; Set consulting engagement workshop Walker Data help implement spopt project. Send note kyle@walker-data.com interested; File issue - even better, pull request - https://github.com/walkerke/spopt-r/issues. stay top package updates / new features get information trainings, sure sign Walker Data mailing list .","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic Zoning Procedure (AZP) — azp","title":"Automatic Zoning Procedure (AZP) — azp","text":"Performs regionalization using Automatic Zoning Procedure algorithm. AZP uses local search minimize within-region heterogeneity maintaining spatial contiguity. Three variants available: basic (greedy), tabu search, simulated annealing.","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic Zoning Procedure (AZP) — azp","text":"","code":"azp(   data,   attrs = NULL,   n_regions,   weights = \"queen\",   bridge_islands = FALSE,   method = c(\"tabu\", \"basic\", \"sa\"),   max_iterations = 100L,   tabu_length = 10L,   cooling_rate = 0.99,   initial_temperature = 0,   scale = TRUE,   seed = NULL,   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic Zoning Procedure (AZP) — azp","text":"data sf object polygon point geometries. attrs Character vector column names use clustering (e.g., c(\"var1\", \"var2\")). NULL, uses numeric columns. n_regions Integer. Number regions (clusters) create. weights Spatial weights specification. Can : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors nb object spdep created sp_weights() list weight types: list(type = \"knn\", k = 6) k-nearest neighbors, list(type = \"distance\", d = 5000) distance-based weights bridge_islands Logical. TRUE, automatically connect disconnected components (e.g., islands) using nearest-neighbor edges. FALSE (default), function error spatial weights graph disconnected. method Character. Optimization method: \"basic\" (greedy local search), \"tabu\" (tabu search), \"sa\" (simulated annealing). Default \"tabu\". max_iterations Integer. Maximum number iterations (default 100). tabu_length Integer. Length tabu list tabu method (default 10). cooling_rate Numeric. Cooling rate SA method, 0 1 (default 0.99). initial_temperature Numeric. Initial temperature SA method. 0 (default), automatically set based initial objective. scale Logical. TRUE (default), standardize attributes clustering. seed Optional integer reproducibility. verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic Zoning Procedure (AZP) — azp","text":"sf object .region column containing cluster assignments. Metadata stored \"spopt\" attribute, including: algorithm: \"azp\" method: optimization method used n_regions: Number regions created objective: Total within-region sum squared deviations solve_time: Time solve seconds","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatic Zoning Procedure (AZP) — azp","text":"Automatic Zoning Procedure (AZP) introduced Openshaw (1977) refined Openshaw & Rao (1995). local search algorithm : Starts initial random partition n_regions Iteratively moves border areas regions reduce heterogeneity Maintains spatial contiguity throughout Terminates improving moves found Three variants available: basic: Greedy local search accepts improving moves tabu: Tabu search can accept non-improving moves escape local optima, tabu list preventing cycling sa: Simulated annealing accepts worse moves decreasing probability temperature cools","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Automatic Zoning Procedure (AZP) — azp","text":"Openshaw, S. (1977). geographical solution scale aggregation problems region-building, partitioning spatial modelling. Transactions Institute British Geographers, 2(4), 459-472. Openshaw, S., & Rao, L. (1995). Algorithms reengineering 1991 Census geography. Environment Planning , 27(3), 425-446.","code":""},{"path":"https://walker-data.com/spopt/reference/azp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic Zoning Procedure (AZP) — azp","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Basic AZP with 8 regions result <- azp(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8)  # Tabu search (often finds better solutions) result <- azp(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8,               method = \"tabu\", tabu_length = 15)  # Simulated annealing result <- azp(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8,               method = \"sa\", cooling_rate = 0.95)  # View results plot(result[\".region\"]) } # }"},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":null,"dir":"Reference","previous_headings":"","what":"Capacitated Facility Location Problem (CFLP) — cflp","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"Solves Capacitated Facility Location Problem: minimize total weighted distance demand points facilities, subject capacity constraints facility. Unlike standard p-median, facilities limited capacity demand may need split across multiple facilities.","code":""},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"","code":"cflp(   demand,   facilities,   n_facilities,   weight_col,   capacity_col,   facility_cost_col = NULL,   cost_matrix = NULL,   distance_metric = \"euclidean\",   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"demand sf object representing demand points. facilities sf object representing candidate facility locations. n_facilities Integer. Number facilities locate. Set 0 using facility_cost_col determine optimal number. weight_col Character. Column name demand containing demand weights (e.g., population, customers, volume). capacity_col Character. Column name facilities containing capacity facility. facility_cost_col Optional character. Column name facilities containing fixed cost open facility. provided n_facilities = 0, solver determines optimal number facilities minimize total cost. cost_matrix Optional. Pre-computed distance/cost matrix (demand x facilities). distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"list two sf objects: $demand: Original demand sf .facility column (primary assignment) .split column (TRUE demand split across facilities) $facilities: Original facilities sf .selected, .n_assigned, .utilization columns Metadata stored \"spopt\" attribute, including: objective: Total cost (transportation + facility costs applicable) mean_distance: Mean weighted distance n_split_demand: Number demand points split across facilities allocation_matrix: Full allocation matrix (n_demand x n_facilities)","code":""},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"CFLP extends p-median problem adding capacity constraints. facility \\(j\\) maximum capacity \\(Q_j\\), total demand assigned exceed capacity. demand exceeds available capacity nearest facility, solver may split demand across multiple facilities. .split column indicates demand points split, allocation_matrix metadata shows exact fractions. Two modes operation: Fixed number: Set n_facilities select exactly many facilities Cost-based: Set n_facilities = 0 provide facility_cost_col let solver determine optimal number based fixed + variable costs","code":""},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"Daskin, M. S. (2013). Network discrete location: Models, algorithms, applications (2nd ed.). John Wiley & Sons. doi:10.1002/9781118537015 Sridharan, R. (1995). capacitated plant location problem. European Journal Operational Research, 87(2), 203-213. doi:10.1016/0377-2217(95)00042-O","code":""},{"path":"https://walker-data.com/spopt/reference/cflp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Capacitated Facility Location Problem (CFLP) — cflp","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  # Demand points with population demand <- st_as_sf(data.frame(   x = runif(100), y = runif(100), population = rpois(100, 500) ), coords = c(\"x\", \"y\"))  # Facilities with varying capacities facilities <- st_as_sf(data.frame(   x = runif(15), y = runif(15),   capacity = c(rep(5000, 5), rep(10000, 5), rep(20000, 5)),   fixed_cost = c(rep(100, 5), rep(200, 5), rep(400, 5)) ), coords = c(\"x\", \"y\"))  # Fixed number of facilities result <- cflp(demand, facilities, n_facilities = 5,                weight_col = \"population\", capacity_col = \"capacity\")  # Check utilization result$facilities[result$facilities$.selected, c(\"capacity\", \".utilization\")]  # Cost-based (optimal number of facilities) result <- cflp(demand, facilities, n_facilities = 0,                weight_col = \"population\", capacity_col = \"capacity\",                facility_cost_col = \"fixed_cost\") attr(result, \"spopt\")$n_selected } # }"},{"path":"https://walker-data.com/spopt/reference/distance_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute distance matrix between sf objects — distance_matrix","title":"Compute distance matrix between sf objects — distance_matrix","text":"Computes pairwise distances geometries. geographic (longlat) coordinate systems, uses great circle distances meters via sf::st_distance(). projected coordinate systems, uses fast Euclidean distance CRS units (typically meters).","code":""},{"path":"https://walker-data.com/spopt/reference/distance_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute distance matrix between sf objects — distance_matrix","text":"","code":"distance_matrix(   x,   y = NULL,   type = c(\"euclidean\", \"manhattan\"),   use_centroids = NULL )"},{"path":"https://walker-data.com/spopt/reference/distance_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute distance matrix between sf objects — distance_matrix","text":"x sf object (demand points facility location, areas regionalization). y sf object (facility locations). NULL, computes distances within x. type Distance type: \"euclidean\" (default) \"manhattan\". Note geographic CRS, \"euclidean\" (great circle) distance available. use_centroids Logical. TRUE (default polygons), use polygon centroids.","code":""},{"path":"https://walker-data.com/spopt/reference/distance_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute distance matrix between sf objects — distance_matrix","text":"numeric matrix distances. Rows correspond x, columns y. geographic CRS, distances meters. projected CRS, distances CRS units (usually meters).","code":""},{"path":"https://walker-data.com/spopt/reference/distance_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute distance matrix between sf objects — distance_matrix","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) demand <- st_as_sf(data.frame(x = runif(10), y = runif(10)), coords = c(\"x\", \"y\")) facilities <- st_as_sf(data.frame(x = runif(5), y = runif(5)), coords = c(\"x\", \"y\")) d <- distance_matrix(demand, facilities) } # }"},{"path":"https://walker-data.com/spopt/reference/distance_matrix_geographic.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute distance matrix for geographic CRS using sf::st_distance — distance_matrix_geographic","title":"Compute distance matrix for geographic CRS using sf::st_distance — distance_matrix_geographic","text":"Internal function uses sf::st_distance() accurate great circle distances geographic (longlat) coordinate systems.","code":""},{"path":"https://walker-data.com/spopt/reference/distance_matrix_geographic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute distance matrix for geographic CRS using sf::st_distance — distance_matrix_geographic","text":"","code":"distance_matrix_geographic(x, y = NULL, use_centroids = NULL)"},{"path":"https://walker-data.com/spopt/reference/distance_matrix_geographic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute distance matrix for geographic CRS using sf::st_distance — distance_matrix_geographic","text":"x sf object y sf object NULL use_centroids Logical. TRUE, use polygon centroids.","code":""},{"path":"https://walker-data.com/spopt/reference/distance_matrix_geographic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute distance matrix for geographic CRS using sf::st_distance — distance_matrix_geographic","text":"numeric matrix distances meters.","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":null,"dir":"Reference","previous_headings":"","what":"Flow Refueling Location Model (FRLM) — frlm","title":"Flow Refueling Location Model (FRLM) — frlm","text":"Solves Flow Refueling Location Model optimally place refueling facilities along network paths. model maximizes volume origin-destination flows can served given vehicle range constraints.","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flow Refueling Location Model (FRLM) — frlm","text":"","code":"frlm(   flows,   candidates,   network = NULL,   vehicle_range,   n_facilities,   method = c(\"greedy\"),   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flow Refueling Location Model (FRLM) — frlm","text":"flows data frame sf object containing flow information columns: origin: Origin identifier destination: Destination identifier volume: Flow volume (e.g., number trips) candidates sf object candidate facility locations (points). network Optional. distance matrix candidates. NULL (default), Euclidean distances computed candidate geometries. network distances, compute externally using packages like r5r dodgr pass resulting matrix . vehicle_range Numeric. Maximum vehicle range (units network distances). n_facilities Integer. Number facilities place. method Character. Optimization method: \"greedy\" (default currently option). verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flow Refueling Location Model (FRLM) — frlm","text":"list class \"spopt_frlm\" containing: facilities: candidates sf object .selected column selected_indices: 1-based indices selected facilities coverage: Coverage statistics Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Flow Refueling Location Model (FRLM) — frlm","text":"Flow Refueling Location Model (Kuby & Lim, 2005) addresses problem locating refueling stations range-limited vehicles (e.g., electric vehicles, hydrogen fuel cell vehicles) along travel paths. flow (origin-destination path) \"covered\" vehicle can complete round trip refueling stops selected facilities. model assumes: Vehicles start origin half tank (can travel R/2) open station, vehicles refuel full (can travel R) round trip must completable without running fuel flow covered, three conditions must met: First open station must within R/2 origin (half-tank start) subsequent open station must within R previous Last open station must within R/2 destination (allow return) implementation uses greedy heuristic iteratively selects facility providing greatest marginal increase covered flow volume.","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"input-format","dir":"Reference","previous_headings":"","what":"Input Format","title":"Flow Refueling Location Model (FRLM) — frlm","text":"simple cases, can provide: flows: Data frame origin, destination, volume candidates: sf points potential facility locations network: Pre-computed distance matrix (optional)","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flow Refueling Location Model (FRLM) — frlm","text":"Kuby, M., & Lim, S. (2005). flow-refueling location problem alternative-fuel vehicles. Socio-Economic Planning Sciences, 39(2), 125-145. doi:10.1016/j.seps.2004.03.001 Capar, ., & Kuby, M. (2012). efficient formulation flow refueling location model alternative-fuel stations. IIE Transactions, 44(8), 622-636. doi:10.1080/0740817X.2011.635175","code":""},{"path":"https://walker-data.com/spopt/reference/frlm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flow Refueling Location Model (FRLM) — frlm","text":"","code":"if (FALSE) { # \\dontrun{ # Simple example with distance matrix library(sf)  # Create candidate locations candidates <- st_as_sf(data.frame(   id = 1:10,   x = runif(10, 0, 100),   y = runif(10, 0, 100) ), coords = c(\"x\", \"y\"))  # Create flows (using candidate indices as origins/destinations) flows <- data.frame(   origin = c(1, 1, 3, 5),   destination = c(8, 10, 7, 9),   volume = c(100, 200, 150, 300) )  # Solve with vehicle range of 50 units result <- frlm(flows, candidates, vehicle_range = 50, n_facilities = 3)  # View selected facilities result$facilities[result$facilities$.selected, ] } # }"},{"path":"https://walker-data.com/spopt/reference/huff.html","id":null,"dir":"Reference","previous_headings":"","what":"Huff Model for Market Share Analysis — huff","title":"Huff Model for Market Share Analysis — huff","text":"Computes probability surfaces predict market share sales potential based distance decay store attractiveness. Huff model widely used retail site selection estimate probability consumer given location choose particular store.","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Huff Model for Market Share Analysis — huff","text":"","code":"huff(   demand,   stores,   attractiveness_col,   attractiveness_exponent = 1,   distance_exponent = -1.5,   sales_potential_col = NULL,   cost_matrix = NULL,   distance_metric = \"euclidean\" )"},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Huff Model for Market Share Analysis — huff","text":"demand sf object representing demand points areas. Can customer locations, census block groups, grid cells, etc. stores sf object representing store/facility locations. attractiveness_col Character vector. Column name(s) stores containing attractiveness values (e.g., square footage, parking spaces). Multiple columns can specified composite attractiveness. attractiveness_exponent Numeric vector. Exponent(s) attractiveness (default 1). Must length attractiveness_col length 1 (recycled). Higher values increase importance variable. distance_exponent Numeric. Distance decay exponent (default -1.5). negative; negative = faster decay distance. sales_potential_col Optional character. Column name demand containing sales potential values (e.g., disposable income, population). NULL, demand point weighted equally. cost_matrix Optional. Pre-computed distance/cost matrix (demand x stores). NULL, Euclidean distance computed geometries. distance_metric Distance metric cost_matrix NULL: \"euclidean\" (default) \"manhattan\".","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Huff Model for Market Share Analysis — huff","text":"list : $demand: Original demand sf added columns: .primary_store: ID highest-probability store .entropy: Competition measure (higher = competition) .prob_<store_id>: Probability columns store $stores: Original stores sf added columns: .market_share: Proportion total market captured .expected_sales: Expected sales (sum prob × potential) $probability_matrix: Full probability matrix (n_demand × n_stores) Metadata \"spopt\" attribute includes parameters used.","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Huff Model for Market Share Analysis — huff","text":"Huff model calculates probability consumer location choose store j using: $$P_{ij} = \\frac{A_j \\times D_{ij}^\\beta}{\\sum_k A_k \\times D_{ik}^\\beta}$$ : \\(A_j\\) composite attractiveness store j \\(D_{ij}\\) distance j \\(\\beta\\) distance decay exponent (default -1.5) multiple attractiveness variables specified, composite attractiveness computed : $$A_j = \\prod_m V_{jm}^{\\alpha_m}$$ \\(V_{jm}\\) value attractiveness variable m store j, \\(\\alpha_m\\) corresponding exponent. distance exponent typically negative probability decreases distance. Common values range -1 -3.","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"outputs","dir":"Reference","previous_headings":"","what":"Outputs","title":"Huff Model for Market Share Analysis — huff","text":"Market Share: weighted average probability across demand points, representing proportion total market potential captured store. Expected Sales: sum (probability × sales_potential) store, representing expected sales volume. Entropy: measure local competition. Higher entropy indicates competitive areas multiple stores similar probabilities.","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Huff Model for Market Share Analysis — huff","text":"Huff, D. L. (1963). Probabilistic Analysis Shopping Center Trade Areas. Land Economics, 39(1), 81-90. doi:10.2307/3144521 Huff, D. L. (1964). Defining Estimating Trading Area. Journal Marketing, 28(3), 34-38. doi:10.1177/002224296402800307","code":""},{"path":"https://walker-data.com/spopt/reference/huff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Huff Model for Market Share Analysis — huff","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  # Create demand grid with spending potential demand <- st_as_sf(expand.grid(x = 1:10, y = 1:10), coords = c(\"x\", \"y\")) demand$spending <- runif(100, 1000, 5000)  # Existing stores with varying sizes (attractiveness) stores <- st_as_sf(data.frame(   id = c(\"Store_A\", \"Store_B\", \"Store_C\"),   sqft = c(50000, 25000, 75000),   parking = c(200, 100, 300),   x = c(2, 8, 5), y = c(2, 8, 5) ), coords = c(\"x\", \"y\"))  # Single attractiveness variable result <- huff(demand, stores,                attractiveness_col = \"sqft\",                distance_exponent = -2,                sales_potential_col = \"spending\")  # Multiple attractiveness variables with different exponents # Composite: A = sqft^1.0 * parking^0.5 result_multi <- huff(demand, stores,                      attractiveness_col = c(\"sqft\", \"parking\"),                      attractiveness_exponent = c(1.0, 0.5),                      distance_exponent = -2,                      sales_potential_col = \"spending\")  # View market shares result_multi$stores[, c(\"id\", \"sqft\", \"parking\", \".market_share\", \".expected_sales\")]  # Evaluate a new candidate store candidate <- st_as_sf(data.frame(   id = \"New_Store\", sqft = 40000, parking = 250, x = 3, y = 7 ), coords = c(\"x\", \"y\"))  all_stores <- rbind(stores, candidate) result_with_candidate <- huff(demand, all_stores,                               attractiveness_col = c(\"sqft\", \"parking\"),                               attractiveness_exponent = c(1.0, 0.5),                               distance_exponent = -2,                               sales_potential_col = \"spending\")  # Compare market shares with and without candidate result_with_candidate$stores[, c(\"id\", \".market_share\")] } # }"},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":null,"dir":"Reference","previous_headings":"","what":"Location Set Covering Problem (LSCP) — lscp","title":"Location Set Covering Problem (LSCP) — lscp","text":"Solves Location Set Covering Problem: find minimum number facilities needed cover demand points within given service radius.","code":""},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Location Set Covering Problem (LSCP) — lscp","text":"","code":"lscp(   demand,   facilities,   service_radius,   cost_matrix = NULL,   distance_metric = \"euclidean\",   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Location Set Covering Problem (LSCP) — lscp","text":"demand sf object representing demand points (polygons, using centroids). facilities sf object representing candidate facility locations. service_radius Numeric. Maximum distance facility cover demand point. cost_matrix Optional. Pre-computed distance matrix (demand x facilities). NULL, computed geometries. distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Location Set Covering Problem (LSCP) — lscp","text":"list two sf objects: $demand: Original demand sf .covered column (logical) $facilities: Original facilities sf .selected column (logical) Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Location Set Covering Problem (LSCP) — lscp","text":"LSCP minimizes number facilities required ensure every demand point within service radius least one facility. mandatory coverage model full coverage required. integer programming formulation : $$\\min \\sum_j y_j$$ Subject : $$\\sum_j a_{ij} y_j \\geq 1 \\quad \\forall $$ $$y_j \\\\{0,1\\}$$ \\(y_j = 1\\) facility j selected, \\(a_{ij} = 1\\) facility j can cover demand point (distance \\(\\leq\\) service radius).","code":""},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"Location Set Covering Problem (LSCP) — lscp","text":"LSCP appropriate complete coverage mandatory: Emergency services: Fire stations, ambulance depots, hospitals every resident must reachable within response time standard Public services: Schools, polling places, post offices universal access required law policy Infrastructure: Cell towers utility substations gaps coverage unacceptable Retail/logistics: Warehouse locations ensure customers can receive -day next-day delivery situations complete coverage required feasible within budget constraints, consider mclp() instead.","code":""},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Location Set Covering Problem (LSCP) — lscp","text":"Toregas, C., Swain, R., ReVelle, C., & Bergman, L. (1971). Location Emergency Service Facilities. Operations Research, 19(6), 1363-1373. doi:10.1287/opre.19.6.1363","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/reference/lscp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Location Set Covering Problem (LSCP) — lscp","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  # Create demand and facility points demand <- st_as_sf(data.frame(x = runif(50), y = runif(50)), coords = c(\"x\", \"y\")) facilities <- st_as_sf(data.frame(x = runif(10), y = runif(10)), coords = c(\"x\", \"y\"))  # Find minimum facilities to cover all demand within 0.3 units result <- lscp(demand, facilities, service_radius = 0.3)  # View selected facilities result$facilities[result$facilities$.selected, ] } # }"},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":null,"dir":"Reference","previous_headings":"","what":"Max-P Regions — max_p_regions","title":"Max-P Regions — max_p_regions","text":"Perform Max-P regionalization maximize number spatially contiguous regions region satisfies minimum threshold constraint specified attribute. useful creating regions meet minimum population sample size requirements.","code":""},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max-P Regions — max_p_regions","text":"","code":"max_p_regions(   data,   attrs = NULL,   threshold_var,   threshold,   weights = \"queen\",   bridge_islands = FALSE,   compact = FALSE,   compact_weight = 0.5,   n_iterations = 100L,   n_sa_iterations = 100L,   cooling_rate = 0.99,   tabu_length = 10L,   scale = TRUE,   seed = NULL,   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max-P Regions — max_p_regions","text":"data sf object polygon point geometries. attrs Character vector column names use computing within-region dissimilarity (e.g., c(\"var1\", \"var2\")). NULL, uses numeric columns. threshold_var Character. Name column containing threshold variable (e.g., population, income). region must sum variable >= threshold. threshold Numeric. Minimum sum threshold_var required per region. weights Spatial weights specification. Can : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors nb object spdep created sp_weights() list weight types: list(type = \"knn\", k = 6) k-nearest neighbors, list(type = \"distance\", d = 5000) distance-based weights KNN weights guarantee connectivity (islands), can useful datasets disconnected polygons. bridge_islands Logical. TRUE, automatically connect disconnected components (e.g., islands) using nearest-neighbor edges. FALSE (default), function error spatial weights graph disconnected. useful datasets like LA County Catalina Islands, archipelago data physical adjacency exist regionalization still desired. compact Logical. TRUE, optimize region compactness addition attribute homogeneity. Compact regions regular shapes, useful sales territories, patrol areas, electoral districts. Default FALSE. compact_weight Numeric 0 1. Weight compactness vs attribute homogeneity compact = TRUE. Higher values prioritize compact shapes attribute similarity. Default 0.5. n_iterations Integer. Number construction phase iterations (default 100). Higher values explore random starting solutions. n_sa_iterations Integer. Number simulated annealing iterations (default 100). Set 0 skip SA refinement phase. cooling_rate Numeric. SA cooling rate 0 1 (default 0.99). Smaller values cool faster, larger values allow exploration. tabu_length Integer. Length tabu list SA phase (default 10). scale Logical. TRUE (default), standardize attributes computing dissimilarity. seed Optional integer reproducibility. verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Max-P Regions — max_p_regions","text":"sf object .region column containing region assignments. Metadata stored \"spopt\" attribute, including: algorithm: \"max_p\" n_regions: Number regions created (\"p\" max-p) objective: Total within-region sum squared deviations threshold_var: Name threshold variable threshold: Threshold value used solve_time: Time solve seconds mean_compactness: Mean Polsby-Popper compactness (compact = TRUE) region_compactness: Per-region compactness scores (compact = TRUE)","code":""},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Max-P Regions — max_p_regions","text":"Max-P algorithm (Duque, Anselin & Rey, 2012; Wei, Rey & Knaap, 2021) solves problem aggregating n geographic areas maximum number homogeneous regions ensuring: region spatially contiguous (connected) region satisfies minimum threshold specified attribute algorithm two phases: Construction phase: Builds feasible solutions via randomized greedy region growing. Multiple random starts explored parallel. Simulated annealing phase: Refines solutions moving border areas regions minimize within-region dissimilarity respecting constraints. compact = TRUE, algorithm additionally optimizes compact region shapes based Feng, Rey, & Wei (2022). Compact regions: Minimize travel time within regions (useful service territories) Reduce gerrymandering potential (electoral districts) Often result finding regions due efficient space usage Compactness metric: implementation uses centroid dispersion measure optimization, rather Normalized Moment Inertia (NMI) described Feng et al. (2022). design choice provides two advantages: Point-based regionalization: algorithm works polygon point geometries. point data, use KNN distance-based weights (e.g., weights = list(type = \"knn\", k = 6)). Computational efficiency: Centroid dispersion O(n) per region versus O(v) NMI v = total polygon vertices. polygon data, centroids computed via sf::st_centroid(). Users aware centroid-based compactness may less accurate highly irregular shapes large, sparsely-populated areas centroid poorly represents polygon's spatial extent. reported mean_compactness region_compactness results use Polsby-Popper (4piA/P^2), standard geometric compactness measure polygons. point data, metrics computed. implementation optimized speed using: Parallel construction early termination Efficient articulation point detection move eligibility Incremental threshold tracking","code":""},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Max-P Regions — max_p_regions","text":"Duque, J. C., Anselin, L., & Rey, S. J. (2012). max-p-regions problem. Journal Regional Science, 52(3), 397-419. Wei, R., Rey, S., & Knaap, E. (2021). Efficient regionalization spatially explicit neighborhood delineation. International Journal Geographical Information Science, 35(1), 135-151. doi:10.1080/13658816.2020.1759806 Feng, X., Rey, S., & Wei, R. (2022). max-p-compact-regions problem. Transactions GIS, 26, 717-734. doi:10.1111/tgis.12874","code":""},{"path":"https://walker-data.com/spopt/reference/max_p_regions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Max-P Regions — max_p_regions","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Create regions where each has at least 100,000 in BIR74 result <- max_p_regions(   nc,   attrs = c(\"SID74\", \"SID79\"),   threshold_var = \"BIR74\",   threshold = 100000 )  # Check number of regions created attr(result, \"spopt\")$n_regions  # With compactness optimization (for sales territories) result_compact <- max_p_regions(   nc,   attrs = c(\"SID74\", \"SID79\"),   threshold_var = \"BIR74\",   threshold = 100000,   compact = TRUE,   compact_weight = 0.5 )  # Check compactness attr(result_compact, \"spopt\")$mean_compactness  # Plot results plot(result[\".region\"])  # Point-based regionalization (e.g., store locations, sensor networks) # Use KNN weights since points don't have polygon contiguity points <- st_as_sf(data.frame(   x = runif(200), y = runif(200),   customers = rpois(200, 100),   avg_income = rnorm(200, 50000, 15000) ), coords = c(\"x\", \"y\"))  result_points <- max_p_regions(   points,   attrs = \"avg_income\",   threshold_var = \"customers\",   threshold = 500,   weights = list(type = \"knn\", k = 6),   compact = TRUE ) } # }"},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Coverage Location Problem (MCLP) — mclp","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"Solves Maximum Coverage Location Problem: maximize total weighted demand covered locating exactly p facilities.","code":""},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"","code":"mclp(   demand,   facilities,   service_radius,   n_facilities,   weight_col,   cost_matrix = NULL,   distance_metric = \"euclidean\",   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"demand sf object representing demand points. facilities sf object representing candidate facility locations. service_radius Numeric. Maximum distance coverage. n_facilities Integer. Number facilities locate (p). weight_col Character. Column name demand containing demand weights. cost_matrix Optional. Pre-computed distance matrix. distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"list two sf objects: $demand: Original demand sf .covered .facility columns $facilities: Original facilities sf .selected column Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"MCLP maximizes total weighted demand covered locating exactly p facilities. Unlike lscp(), requires full coverage, MCLP accepts partial coverage optimizes best possible outcome given fixed budget (number facilities). integer programming formulation : $$\\max \\sum_i w_i z_i$$ Subject : $$\\sum_j y_j = p$$ $$z_i \\leq \\sum_j a_{ij} y_j \\quad \\forall $$ $$y_j, z_i \\\\{0,1\\}$$ \\(w_i\\) weight (demand) location , \\(y_j = 1\\) facility j selected, \\(z_i = 1\\) demand covered, \\(a_{ij} = 1\\) facility j can cover demand .","code":""},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"MCLP appropriate fixed budget capacity constraint: Healthcare access: Locating p clinics maximize population within 30-minute drive, given limited funding Retail site selection: Choosing p store locations maximize number potential customers within trade area Emergency services: Placing p ambulance stations maximize population reachable within 8-minute response time Conservation: Selecting p reserve sites maximize number species habitat area protected Telecommunications: Locating p cell towers maximize population coverage full coverage economically feasible situations complete coverage required, use lscp() find minimum number facilities needed.","code":""},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"Church, R., & ReVelle, C. (1974). Maximal Covering Location Problem. Papers Regional Science, 32(1), 101-118. doi:10.1007/BF01942293","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/reference/mclp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Coverage Location Problem (MCLP) — mclp","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  # Create demand with weights demand <- st_as_sf(data.frame(   x = runif(50), y = runif(50), population = rpois(50, 100) ), coords = c(\"x\", \"y\")) facilities <- st_as_sf(data.frame(x = runif(10), y = runif(10)), coords = c(\"x\", \"y\"))  # Maximize population coverage with 3 facilities result <- mclp(demand, facilities, service_radius = 0.3,                n_facilities = 3, weight_col = \"population\")  attr(result, \"spopt\")$coverage_pct } # }"},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":null,"dir":"Reference","previous_headings":"","what":"P-Center Problem — p_center","title":"P-Center Problem — p_center","text":"Solves P-Center problem: minimize maximum distance demand point nearest facility locating exactly p facilities. equity-focused (minimax) objective ensures demand point far service.","code":""},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"P-Center Problem — p_center","text":"","code":"p_center(   demand,   facilities,   n_facilities,   cost_matrix = NULL,   distance_metric = \"euclidean\",   method = c(\"binary_search\", \"mip\"),   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"P-Center Problem — p_center","text":"demand sf object representing demand points. facilities sf object representing candidate facility locations. n_facilities Integer. Number facilities locate (p). cost_matrix Optional. Pre-computed distance matrix. distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". method Algorithm use: \"binary_search\" (default, faster) \"mip\" (direct mixed-integer programming formulation). verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"P-Center Problem — p_center","text":"list two sf objects: $demand: Original demand sf .facility column $facilities: Original facilities sf .selected column Metadata includes max_distance (objective value).","code":""},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"P-Center Problem — p_center","text":"p-center problem minimizes maximum distance demand point assigned facility. \"minimax\" objective ensures equitable access focusing worst-served location rather average performance. Two algorithms available: \"binary_search\" (default): Binary search distances set covering subproblems. converts difficult minimax objective simpler feasibility problems typically much faster. \"mip\": Direct mixed-integer programming formulation minimax objective. Can slower may preferred small problems exact optimality certificates needed. direct MIP formulation : $$\\min W$$ Subject : $$\\sum_j y_j = p$$ $$\\sum_j x_{ij} = 1 \\quad \\forall $$ $$x_{ij} \\leq y_j \\quad \\forall ,j$$ $$\\sum_j d_{ij} x_{ij} \\leq W \\quad \\forall $$ $$x_{ij}, y_j \\\\{0,1\\}$$ W maximum distance minimize, \\(d_{ij}\\) distance demand facility j, \\(x_{ij} = 1\\) demand assigned facility j, \\(y_j = 1\\) facility j selected.","code":""},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"P-Center Problem — p_center","text":"P-center appropriate equity worst-case performance matter: Emergency services: Fire stations ambulance depots response time standards must met residents Equity-focused planning: Ensuring community underserved, even increases average travel distance Critical infrastructure: Backup facilities emergency shelters everyone must within reach Service level guarantees: contracts regulations specify maximum acceptable distance response time efficiency-focused objectives minimize total travel, consider p_median() instead.","code":""},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"P-Center Problem — p_center","text":"Hakimi, S. L. (1965). Optimum Distribution Switching Centers Communication Network Related Graph Theoretic Problems. Operations Research, 13(3), 462-475. doi:10.1287/opre.13.3.462","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/reference/p_center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"P-Center Problem — p_center","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  demand <- st_as_sf(data.frame(x = runif(50), y = runif(50)), coords = c(\"x\", \"y\")) facilities <- st_as_sf(data.frame(x = runif(15), y = runif(15)), coords = c(\"x\", \"y\"))  # Minimize maximum distance with 4 facilities result <- p_center(demand, facilities, n_facilities = 4)  # Maximum distance any demand point must travel attr(result, \"spopt\")$max_distance } # }"},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"P-Dispersion Problem — p_dispersion","title":"P-Dispersion Problem — p_dispersion","text":"Solves P-Dispersion problem: maximize minimum distance two selected facilities. \"maximin\" objective ensures facilities spread much possible.","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"P-Dispersion Problem — p_dispersion","text":"","code":"p_dispersion(   facilities,   n_facilities,   cost_matrix = NULL,   distance_metric = \"euclidean\",   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"P-Dispersion Problem — p_dispersion","text":"facilities sf object representing candidate facility locations. Note: problem use demand points. n_facilities Integer. Number facilities locate (p). cost_matrix Optional. Pre-computed inter-facility distance matrix. distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"P-Dispersion Problem — p_dispersion","text":"sf object (facilities input) .selected column. Metadata includes min_distance (objective value).","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"P-Dispersion Problem — p_dispersion","text":"p-dispersion problem selects p facilities set candidates minimum pairwise distance two selected facilities maximized. Unlike p-median p-center, problem consider demand points—focuses solely spreading facilities apart. mixed integer programming formulation uses Big-M approach: $$\\max D$$ Subject : $$\\sum_j y_j = p$$ $$D \\leq d_{ij} + M(2 - y_i - y_j) \\quad \\forall < j$$ $$y_j \\\\{0,1\\}, \\quad D \\geq 0$$ D minimum separation distance maximize, \\(d_{ij}\\) distance facilities j, \\(y_j = 1\\) facility j selected, M large constant. facilities j selected (\\(y_i = y_j = 1\\)), constraint reduces \\(D \\leq d_{ij}\\), ensuring D distance pair selected facilities.","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"P-Dispersion Problem — p_dispersion","text":"P-dispersion appropriate facilities spread apart: Obnoxious facilities: Hazardous waste sites, prisons, undesirable facilities separated Franchise territories: Retail locations stores cannibalize 's market Redundant systems: Backup servers emergency caches geographically distributed resilience Monitoring networks: Air quality sensors seismic monitors cover distinct areas without overlap Spatial sampling: Selecting representative sample locations well-distributed across study area","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"P-Dispersion Problem — p_dispersion","text":"Kuby, M. J. (1987). Programming Models Facility Dispersion: p-Dispersion Maxisum Dispersion Problems. Geographical Analysis, 19(4), 315-329. doi:10.1111/j.1538-4632.1987.tb00133.x","code":""},{"path":"https://walker-data.com/spopt/reference/p_dispersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"P-Dispersion Problem — p_dispersion","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  facilities <- st_as_sf(data.frame(x = runif(20), y = runif(20)), coords = c(\"x\", \"y\"))  # Select 5 facilities maximally dispersed result <- p_dispersion(facilities, n_facilities = 5)  # Minimum distance between any two selected facilities attr(result, \"spopt\")$min_distance } # }"},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":null,"dir":"Reference","previous_headings":"","what":"P-Median Problem — p_median","title":"P-Median Problem — p_median","text":"Solves P-Median problem: minimize total weighted distance demand points assigned facilities locating exactly p facilities. efficiency-focused objective minimizes overall travel burden.","code":""},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"P-Median Problem — p_median","text":"","code":"p_median(   demand,   facilities,   n_facilities,   weight_col,   cost_matrix = NULL,   distance_metric = \"euclidean\",   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"P-Median Problem — p_median","text":"demand sf object representing demand points. facilities sf object representing candidate facility locations. n_facilities Integer. Number facilities locate (p). weight_col Character. Column name demand containing demand weights. cost_matrix Optional. Pre-computed distance matrix. distance_metric Distance metric: \"euclidean\" (default) \"manhattan\". verbose Logical. Print solver progress.","code":""},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"P-Median Problem — p_median","text":"list two sf objects: $demand: Original demand sf .facility column (assigned facility) $facilities: Original facilities sf .selected .n_assigned columns Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"P-Median Problem — p_median","text":"p-median problem minimizes total weighted distance (travel cost) demand points nearest assigned facility. widely used location model efficiency-oriented facility siting. integer programming formulation : $$\\min \\sum_i \\sum_j w_i d_{ij} x_{ij}$$ Subject : $$\\sum_j y_j = p$$ $$\\sum_j x_{ij} = 1 \\quad \\forall $$ $$x_{ij} \\leq y_j \\quad \\forall ,j$$ $$x_{ij}, y_j \\\\{0,1\\}$$ \\(w_i\\) demand weight location , \\(d_{ij}\\) distance demand facility j, \\(x_{ij} = 1\\) demand assigned facility j, \\(y_j = 1\\) facility j selected.","code":""},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"P-Median Problem — p_median","text":"P-median appropriate minimizing total travel cost distance: Public facilities: Schools, libraries, community centers goal minimize total student/patron travel Warehouses distribution: Locating distribution centers minimize total shipping costs customers Healthcare: Positioning clinics minimize aggregate patient travel time across population Service depots: Locating maintenance facilities minimize total technician travel service calls equity-focused objectives demand point far, consider p_center() instead.","code":""},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"P-Median Problem — p_median","text":"Hakimi, S. L. (1964). Optimum Locations Switching Centers Absolute Centers Medians Graph. Operations Research, 12(3), 450-459. doi:10.1287/opre.12.3.450","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/reference/p_median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"P-Median Problem — p_median","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  demand <- st_as_sf(data.frame(   x = runif(100), y = runif(100), population = rpois(100, 500) ), coords = c(\"x\", \"y\")) facilities <- st_as_sf(data.frame(x = runif(20), y = runif(20)), coords = c(\"x\", \"y\"))  # Locate 5 facilities minimizing total weighted distance result <- p_median(demand, facilities, n_facilities = 5, weight_col = \"population\")  # Mean distance to assigned facility attr(result, \"spopt\")$mean_distance } # }"},{"path":"https://walker-data.com/spopt/reference/rust_azp.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve AZP regionalization problem — rust_azp","title":"Solve AZP regionalization problem — rust_azp","text":"Automatic Zoning Procedure basic, tabu, SA variants.","code":""},{"path":"https://walker-data.com/spopt/reference/rust_azp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve AZP regionalization problem — rust_azp","text":"","code":"rust_azp(   attrs,   n_regions,   adj_i,   adj_j,   method,   max_iterations,   tabu_length,   cooling_rate,   initial_temperature,   seed )"},{"path":"https://walker-data.com/spopt/reference/rust_azp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve AZP regionalization problem — rust_azp","text":"attrs Attribute matrix (n x p) n_regions Number regions create adj_i Row indices adjacency (0-based) adj_j Column indices adjacency (0-based) method \"basic\", \"tabu\", \"sa\" max_iterations Maximum iterations tabu_length Tabu list length (tabu method) cooling_rate SA cooling rate (sa method) initial_temperature SA initial temperature (sa method) seed Random seed","code":""},{"path":"https://walker-data.com/spopt/reference/rust_azp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve AZP regionalization problem — rust_azp","text":"List labels, n_regions, objective","code":""},{"path":"https://walker-data.com/spopt/reference/rust_cflp.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve Capacitated Facility Location Problem (CFLP) — rust_cflp","title":"Solve Capacitated Facility Location Problem (CFLP) — rust_cflp","text":"Minimize weighted distance subject facility capacity constraints. Supports fixed number facilities facility opening costs.","code":""},{"path":"https://walker-data.com/spopt/reference/rust_cflp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve Capacitated Facility Location Problem (CFLP) — rust_cflp","text":"","code":"rust_cflp(cost_matrix, weights, capacities, n_facilities, facility_costs)"},{"path":"https://walker-data.com/spopt/reference/rust_cflp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve Capacitated Facility Location Problem (CFLP) — rust_cflp","text":"cost_matrix Cost/distance matrix (demand x facilities) weights Demand weights capacities Capacity facility n_facilities Number facilities locate (0 using facility costs) facility_costs Optional fixed cost open facility","code":""},{"path":"https://walker-data.com/spopt/reference/rust_cflp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve Capacitated Facility Location Problem (CFLP) — rust_cflp","text":"List selected facilities, assignments, utilizations","code":""},{"path":"https://walker-data.com/spopt/reference/rust_connected_components.html","id":null,"dir":"Reference","previous_headings":"","what":"Find connected components — rust_connected_components","title":"Find connected components — rust_connected_components","text":"Find connected components","code":""},{"path":"https://walker-data.com/spopt/reference/rust_connected_components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find connected components — rust_connected_components","text":"","code":"rust_connected_components(i, j, n)"},{"path":"https://walker-data.com/spopt/reference/rust_connected_components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find connected components — rust_connected_components","text":"Row indices adjacency matrix j Column indices adjacency matrix n Number nodes","code":""},{"path":"https://walker-data.com/spopt/reference/rust_connected_components.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find connected components — rust_connected_components","text":"Vector component labels (0-based)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_euclidean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Euclidean distance matrix between two sets of points — rust_distance_matrix_euclidean","title":"Compute Euclidean distance matrix between two sets of points — rust_distance_matrix_euclidean","text":"Compute Euclidean distance matrix two sets points","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_euclidean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Euclidean distance matrix between two sets of points — rust_distance_matrix_euclidean","text":"","code":"rust_distance_matrix_euclidean(x1, y1, x2, y2)"},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_euclidean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Euclidean distance matrix between two sets of points — rust_distance_matrix_euclidean","text":"x1 X coordinates first set points y1 Y coordinates first set points x2 X coordinates second set points y2 Y coordinates second set points","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_euclidean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Euclidean distance matrix between two sets of points — rust_distance_matrix_euclidean","text":"Distance matrix (n1 x n2)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_manhattan.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Manhattan distance matrix between two sets of points — rust_distance_matrix_manhattan","title":"Compute Manhattan distance matrix between two sets of points — rust_distance_matrix_manhattan","text":"Compute Manhattan distance matrix two sets points","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_manhattan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Manhattan distance matrix between two sets of points — rust_distance_matrix_manhattan","text":"","code":"rust_distance_matrix_manhattan(x1, y1, x2, y2)"},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_manhattan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Manhattan distance matrix between two sets of points — rust_distance_matrix_manhattan","text":"x1 X coordinates first set points y1 Y coordinates first set points x2 X coordinates second set points y2 Y coordinates second set points","code":""},{"path":"https://walker-data.com/spopt/reference/rust_distance_matrix_manhattan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Manhattan distance matrix between two sets of points — rust_distance_matrix_manhattan","text":"Distance matrix (n1 x n2)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_frlm_greedy.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve FRLM using greedy heuristic — rust_frlm_greedy","title":"Solve FRLM using greedy heuristic — rust_frlm_greedy","text":"Solve FRLM using greedy heuristic","code":""},{"path":"https://walker-data.com/spopt/reference/rust_frlm_greedy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve FRLM using greedy heuristic — rust_frlm_greedy","text":"","code":"rust_frlm_greedy(   n_candidates,   path_candidates,   path_offsets,   path_distances,   flow_volumes,   vehicle_range,   n_facilities )"},{"path":"https://walker-data.com/spopt/reference/rust_frlm_greedy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve FRLM using greedy heuristic — rust_frlm_greedy","text":"n_candidates Number candidate facility locations path_candidates Flat array candidate indices path path_offsets Start index path path_candidates path_distances Distances candidate along paths flow_volumes Volume flow vehicle_range Maximum vehicle range n_facilities Number facilities place","code":""},{"path":"https://walker-data.com/spopt/reference/rust_frlm_greedy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve FRLM using greedy heuristic — rust_frlm_greedy","text":"List selected facilities coverage info","code":""},{"path":"https://walker-data.com/spopt/reference/rust_huff.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Huff Model probabilities — rust_huff","title":"Compute Huff Model probabilities — rust_huff","text":"Computes probability surface based distance decay attractiveness. Formula: P_ij = (A_j × D_ij^β) / Σ_k(A_k × D_ik^β)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_huff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Huff Model probabilities — rust_huff","text":"","code":"rust_huff(cost_matrix, attractiveness, distance_exponent, sales_potential)"},{"path":"https://walker-data.com/spopt/reference/rust_huff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Huff Model probabilities — rust_huff","text":"cost_matrix Cost/distance matrix (demand x stores) attractiveness Attractiveness values store (pre-computed exponents) distance_exponent Distance decay exponent (typically negative, e.g., -1.5) sales_potential Optional sales potential demand point","code":""},{"path":"https://walker-data.com/spopt/reference/rust_huff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Huff Model probabilities — rust_huff","text":"List probabilities, market shares, expected sales","code":""},{"path":"https://walker-data.com/spopt/reference/rust_is_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if a graph is connected — rust_is_connected","title":"Check if a graph is connected — rust_is_connected","text":"Check graph connected","code":""},{"path":"https://walker-data.com/spopt/reference/rust_is_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if a graph is connected — rust_is_connected","text":"","code":"rust_is_connected(i, j, n)"},{"path":"https://walker-data.com/spopt/reference/rust_is_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if a graph is connected — rust_is_connected","text":"Row indices adjacency matrix j Column indices adjacency matrix n Number nodes","code":""},{"path":"https://walker-data.com/spopt/reference/rust_is_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if a graph is connected — rust_is_connected","text":"TRUE connected, FALSE otherwise","code":""},{"path":"https://walker-data.com/spopt/reference/rust_lscp.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve LSCP (Location Set Covering Problem) — rust_lscp","title":"Solve LSCP (Location Set Covering Problem) — rust_lscp","text":"Solve LSCP (Location Set Covering Problem)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_lscp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve LSCP (Location Set Covering Problem) — rust_lscp","text":"","code":"rust_lscp(cost_matrix, service_radius)"},{"path":"https://walker-data.com/spopt/reference/rust_lscp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve LSCP (Location Set Covering Problem) — rust_lscp","text":"cost_matrix Cost/distance matrix (demand x facilities) service_radius Maximum service distance","code":""},{"path":"https://walker-data.com/spopt/reference/rust_lscp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve LSCP (Location Set Covering Problem) — rust_lscp","text":"List selected facilities coverage","code":""},{"path":"https://walker-data.com/spopt/reference/rust_max_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve Max-P regionalization problem — rust_max_p","title":"Solve Max-P regionalization problem — rust_max_p","text":"Maximize number regions region satisfies minimum threshold constraint spatial extensive attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/rust_max_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve Max-P regionalization problem — rust_max_p","text":"","code":"rust_max_p(   attrs,   threshold_var,   threshold,   adj_i,   adj_j,   n_iterations,   n_sa_iterations,   cooling_rate,   tabu_length,   seed,   centroids_x,   centroids_y,   compact,   compact_weight )"},{"path":"https://walker-data.com/spopt/reference/rust_max_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve Max-P regionalization problem — rust_max_p","text":"attrs Attribute matrix (n x p) computing within-region dissimilarity threshold_var Values threshold variable (e.g., population) threshold Minimum sum required per region adj_i Row indices adjacency (0-based) adj_j Column indices adjacency (0-based) n_iterations Number construction phase iterations n_sa_iterations Number simulated annealing iterations cooling_rate SA cooling rate (e.g., 0.99) tabu_length Tabu list length SA seed Random seed centroids_x X coordinates unit centroids (compactness) centroids_y Y coordinates unit centroids (compactness) compact Whether optimize compactness compact_weight Weight compactness vs dissimilarity (0-1)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_max_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve Max-P regionalization problem — rust_max_p","text":"List labels (1-based), n_regions, objective, compactness","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mclp.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve MCLP (Maximum Coverage Location Problem) — rust_mclp","title":"Solve MCLP (Maximum Coverage Location Problem) — rust_mclp","text":"Solve MCLP (Maximum Coverage Location Problem)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mclp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve MCLP (Maximum Coverage Location Problem) — rust_mclp","text":"","code":"rust_mclp(cost_matrix, weights, service_radius, n_facilities)"},{"path":"https://walker-data.com/spopt/reference/rust_mclp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve MCLP (Maximum Coverage Location Problem) — rust_mclp","text":"cost_matrix Cost/distance matrix (demand x facilities) weights Demand weights service_radius Maximum service distance n_facilities Number facilities locate","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mclp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve MCLP (Maximum Coverage Location Problem) — rust_mclp","text":"List selected facilities coverage","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mst.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute minimum spanning tree from adjacency matrix — rust_mst","title":"Compute minimum spanning tree from adjacency matrix — rust_mst","text":"Compute minimum spanning tree adjacency matrix","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute minimum spanning tree from adjacency matrix — rust_mst","text":"","code":"rust_mst(i, j, weights, n)"},{"path":"https://walker-data.com/spopt/reference/rust_mst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute minimum spanning tree from adjacency matrix — rust_mst","text":"Row indices (0-based) adjacency matrix non-zero entries j Column indices (0-based) adjacency matrix non-zero entries weights Edge weights (distances/dissimilarities) n Number nodes","code":""},{"path":"https://walker-data.com/spopt/reference/rust_mst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute minimum spanning tree from adjacency matrix — rust_mst","text":"List MST edges (, , weight)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_center.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve P-Center facility location problem — rust_p_center","title":"Solve P-Center facility location problem — rust_p_center","text":"Solve P-Center facility location problem","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve P-Center facility location problem — rust_p_center","text":"","code":"rust_p_center(cost_matrix, n_facilities, method)"},{"path":"https://walker-data.com/spopt/reference/rust_p_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve P-Center facility location problem — rust_p_center","text":"cost_matrix Cost/distance matrix (demand x facilities) n_facilities Number facilities locate method Algorithm method: \"binary_search\" (default) \"mip\"","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve P-Center facility location problem — rust_p_center","text":"List selected facilities, assignments, max distance","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_dispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve P-Dispersion facility location problem — rust_p_dispersion","title":"Solve P-Dispersion facility location problem — rust_p_dispersion","text":"Solve P-Dispersion facility location problem","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_dispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve P-Dispersion facility location problem — rust_p_dispersion","text":"","code":"rust_p_dispersion(distance_matrix, n_facilities)"},{"path":"https://walker-data.com/spopt/reference/rust_p_dispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve P-Dispersion facility location problem — rust_p_dispersion","text":"distance_matrix Distance matrix facilities n_facilities Number facilities select","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_dispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve P-Dispersion facility location problem — rust_p_dispersion","text":"List selected facilities min distance","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve P-Median facility location problem — rust_p_median","title":"Solve P-Median facility location problem — rust_p_median","text":"Solve P-Median facility location problem","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve P-Median facility location problem — rust_p_median","text":"","code":"rust_p_median(cost_matrix, weights, n_facilities)"},{"path":"https://walker-data.com/spopt/reference/rust_p_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve P-Median facility location problem — rust_p_median","text":"cost_matrix Cost/distance matrix (demand x facilities) weights Demand weights n_facilities Number facilities locate (p)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_p_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve P-Median facility location problem — rust_p_median","text":"List selected facilities assignments","code":""},{"path":"https://walker-data.com/spopt/reference/rust_skater.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve SKATER regionalization — rust_skater","title":"Solve SKATER regionalization — rust_skater","text":"Solve SKATER regionalization","code":""},{"path":"https://walker-data.com/spopt/reference/rust_skater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve SKATER regionalization — rust_skater","text":"","code":"rust_skater(attrs, adj_i, adj_j, n_regions, floor_var, floor_value, seed)"},{"path":"https://walker-data.com/spopt/reference/rust_skater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve SKATER regionalization — rust_skater","text":"attrs Attribute matrix (n x p) adj_i Row indices adjacency adj_j Column indices adjacency n_regions Number regions create floor_var Optional floor variable values floor_value Minimum floor value per region seed Random seed","code":""},{"path":"https://walker-data.com/spopt/reference/rust_skater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve SKATER regionalization — rust_skater","text":"Vector region labels (1-based)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_spenc.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve SPENC regionalization problem — rust_spenc","title":"Solve SPENC regionalization problem — rust_spenc","text":"Spatially-encouraged spectral clustering.","code":""},{"path":"https://walker-data.com/spopt/reference/rust_spenc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve SPENC regionalization problem — rust_spenc","text":"","code":"rust_spenc(attrs, n_regions, adj_i, adj_j, gamma, seed)"},{"path":"https://walker-data.com/spopt/reference/rust_spenc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve SPENC regionalization problem — rust_spenc","text":"attrs Attribute matrix (n x p) n_regions Number regions create adj_i Row indices adjacency (0-based) adj_j Column indices adjacency (0-based) gamma RBF kernel parameter seed Random seed","code":""},{"path":"https://walker-data.com/spopt/reference/rust_spenc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve SPENC regionalization problem — rust_spenc","text":"List labels, n_regions, objective","code":""},{"path":"https://walker-data.com/spopt/reference/rust_ward_constrained.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve spatially-constrained Ward clustering — rust_ward_constrained","title":"Solve spatially-constrained Ward clustering — rust_ward_constrained","text":"Solve spatially-constrained Ward clustering","code":""},{"path":"https://walker-data.com/spopt/reference/rust_ward_constrained.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve spatially-constrained Ward clustering — rust_ward_constrained","text":"","code":"rust_ward_constrained(attrs, n_regions, adj_i, adj_j)"},{"path":"https://walker-data.com/spopt/reference/rust_ward_constrained.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve spatially-constrained Ward clustering — rust_ward_constrained","text":"attrs Attribute matrix (n x p) n_regions Number regions create adj_i Row indices adjacency (0-based) adj_j Column indices adjacency (0-based)","code":""},{"path":"https://walker-data.com/spopt/reference/rust_ward_constrained.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve spatially-constrained Ward clustering — rust_ward_constrained","text":"List labels, n_regions, objective","code":""},{"path":"https://walker-data.com/spopt/reference/skater.html","id":null,"dir":"Reference","previous_headings":"","what":"SKATER Spatial Clustering — skater","title":"SKATER Spatial Clustering — skater","text":"Performs spatial clustering using SKATER algorithm (Spatial 'K'luster Analysis Tree Edge Removal). algorithm builds minimum spanning tree spatial contiguity graph, iteratively removes edges create spatially contiguous clusters.","code":""},{"path":"https://walker-data.com/spopt/reference/skater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SKATER Spatial Clustering — skater","text":"","code":"skater(   data,   attrs = NULL,   n_regions,   weights = \"queen\",   bridge_islands = FALSE,   floor = NULL,   floor_value = 0,   scale = TRUE,   seed = NULL,   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/skater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SKATER Spatial Clustering — skater","text":"data sf object polygon point geometries. attrs Character vector column names use clustering (e.g., c(\"var1\", \"var2\")). NULL, uses numeric columns. n_regions Integer. Number regions (clusters) create. weights Spatial weights specification. Can : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors nb object spdep created sp_weights() list weight types: list(type = \"knn\", k = 6) k-nearest neighbors, list(type = \"distance\", d = 5000) distance-based weights bridge_islands Logical. TRUE, automatically connect disconnected components (e.g., islands) using nearest-neighbor edges. FALSE (default), function error spatial weights graph disconnected. floor Optional. Column name specifying floor constraint variable. floor_value Numeric. Minimum sum floor variable required per region. used floor specified. scale Logical. TRUE (default), standardize attributes clustering. seed Optional integer reproducibility. verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/skater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SKATER Spatial Clustering — skater","text":"sf object .region column containing cluster assignments. Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/skater.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SKATER Spatial Clustering — skater","text":"Assuncao, R. M., Neves, M. C., Camara, G., & Freitas, C. da C. (2006). Efficient regionalization techniques socio-economic geographical units using minimum spanning trees. International Journal Geographical Information Science, 20(7), 797-811.","code":""},{"path":"https://walker-data.com/spopt/reference/skater.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SKATER Spatial Clustering — skater","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Cluster into 5 regions based on SIDS rates result <- skater(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 5)  # With floor constraint: each region must have at least 100,000 births result <- skater(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 5,                  floor = \"BIR74\", floor_value = 100000)  # View results plot(result[\".region\"]) } # }"},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spatial weights from an sf object — sp_weights","title":"Create spatial weights from an sf object — sp_weights","text":"Constructs spatial weights (neighborhood structure) sf geometries. Wraps spdep functions convenient interface.","code":""},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spatial weights from an sf object — sp_weights","text":"","code":"sp_weights(   data,   type = c(\"queen\", \"rook\", \"knn\", \"distance\"),   k = NULL,   d = NULL,   ... )"},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spatial weights from an sf object — sp_weights","text":"data sf object polygon point geometries. type Type weights. One : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors \"knn\": K-nearest neighbors based centroid distance \"distance\": units within distance threshold neighbors k Number nearest neighbors. Required type = \"knn\". d Distance threshold. Required type = \"distance\". Units match CRS data (e.g., meters projected CRS). ... Additional arguments passed spdep functions.","code":""},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spatial weights from an sf object — sp_weights","text":"neighbors list object (class \"nb\") compatible spdep.","code":""},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create spatial weights from an sf object — sp_weights","text":"Choosing weight type: Use queen/rook polygon data physical adjacency matters Use knn need guaranteed connectivity (isolates) point data Use distance point data interaction depends proximity KNN weights always produce connected graph (k >= 1), making useful datasets islands disconnected polygons.","code":""},{"path":"https://walker-data.com/spopt/reference/sp_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create spatial weights from an sf object — sp_weights","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Queen contiguity (default) w_queen <- sp_weights(nc, type = \"queen\")  # K-nearest neighbors (guarantees connectivity) w_knn <- sp_weights(nc, type = \"knn\", k = 6)  # Distance-based (e.g., 50km for projected data) nc_proj <- st_transform(nc, 32119)  # NC State Plane w_dist <- sp_weights(nc_proj, type = \"distance\", d = 50000) } # }"},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"Performs spectral clustering spatial constraints combining spatial connectivity attribute similarity using kernel methods. approach useful clustering highly non-convex clusters irregular topologies geographic contexts.","code":""},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"","code":"spenc(   data,   attrs = NULL,   n_regions,   weights = \"queen\",   bridge_islands = FALSE,   gamma = 1,   scale = TRUE,   seed = NULL,   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"data sf object polygon point geometries. attrs Character vector column names use clustering (e.g., c(\"var1\", \"var2\")). NULL, uses numeric columns. n_regions Integer. Number regions (clusters) create. weights Spatial weights specification. Can : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors nb object spdep created sp_weights() list weight types: list(type = \"knn\", k = 6) k-nearest neighbors, list(type = \"distance\", d = 5000) distance-based weights bridge_islands Logical. TRUE, automatically connect disconnected components (e.g., islands) using nearest-neighbor edges. FALSE (default), function error spatial weights graph disconnected. gamma Numeric. RBF kernel parameter controlling attribute similarity decay. Larger values = faster decay = local similarity. Default 1. Can also \"auto\" estimate data. scale Logical. TRUE (default), standardize attributes clustering. seed Optional integer reproducibility. verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"sf object .region column containing cluster assignments. Metadata stored \"spopt\" attribute, including: algorithm: \"spenc\" n_regions: Number regions created objective: Within-cluster sum squared distances embedding space gamma: gamma parameter used solve_time: Time solve seconds","code":""},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"SPENC (Wolf, 2021) extends spectral clustering incorporate spatial constraints. algorithm: Computes attribute affinity using RBF (Gaussian) kernel Multiplies element-wise spatial weights (neighbors affinity) Computes normalized Laplacian combined affinity matrix Extracts k smallest eigenvectors spectral embedding Applies k-means clustering embedding Key advantages: Can find non-convex cluster shapes Respects spatial connectivity Balances attribute similarity spatial proximity gamma parameter controls quickly attribute similarity decays distance attribute space. Larger values create localized clusters.","code":""},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"Wolf, L. J. (2021). Spatially-encouraged spectral clustering: technique blending map typologies regionalization. International Journal Geographical Information Science, 35(11), 2356-2373. doi:10.1080/13658816.2021.1934475","code":""},{"path":"https://walker-data.com/spopt/reference/spenc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatially-Encouraged Spectral Clustering (SPENC) — spenc","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Basic SPENC with 8 regions result <- spenc(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8)  # Adjust gamma for different cluster tightness result <- spenc(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8, gamma = 0.5)  # View results plot(result[\".region\"]) } # }"},{"path":"https://walker-data.com/spopt/reference/spopt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"spopt: Spatial Optimization for Regionalization, Facility Location, and Market Analysis — spopt-package","title":"spopt: Spatial Optimization for Regionalization, Facility Location, and Market Analysis — spopt-package","text":"Spatial optimization algorithms regionalization, facility location, market analysis. Includes algorithms spatial clustering (Max-P, AZP, SKATER, SPENC, Ward), optimal facility siting (P-Median, P-Center, MCLP, LSCP, CFLP, P-Dispersion, FRLM), market share analysis (Huff model). Supports network-based travel times via custom cost matrices. Uses Rust backend via 'extendr' performance 'HiGHS' solver mixed-integer programming.","code":""},{"path":[]},{"path":"https://walker-data.com/spopt/reference/spopt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"spopt: Spatial Optimization for Regionalization, Facility Location, and Market Analysis — spopt-package","text":"Maintainer: Kyle Walker kyle@walker-data.com contributors: PySAL Developers (Original Python spopt library) [copyright holder]","code":""},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":null,"dir":"Reference","previous_headings":"","what":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"dataset containing Census tract polygons, candidate facility points, pre-computed driving travel-time matrix Tarrant County, Texas. Used demonstrating facility location algorithms real travel times.","code":""},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"","code":"tarrant_travel_times"},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"list four elements: tracts sf object Census tract polygons including GEOID, NAME, population, geometry columns. demand sf object tract centroid points (demand locations) WGS84 coordinates. candidates sf object 30 randomly sampled candidate facility locations WGS84 coordinates. matrix numeric matrix driving travel times minutes. Rows correspond demand points, columns candidate facilities. Unreachable pairs set Inf.","code":""},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"Census tract data American Community Survey via tidycensus. Road network OpenStreetMap via GeoFabrik. Travel times computed r5r.","code":""},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"travel-time matrix generated using r5r OpenStreetMap road network data clipped Tarrant County. Candidate facilities sampled using set.seed(1983) reproducibility.","code":""},{"path":"https://walker-data.com/spopt/reference/tarrant_travel_times.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tarrant County Travel Time Matrix Example Data — tarrant_travel_times","text":"","code":"data(tarrant_travel_times)  # Access components tracts <- tarrant_travel_times$tracts demand <- tarrant_travel_times$demand candidates <- tarrant_travel_times$candidates ttm <- tarrant_travel_times$matrix  # Use with p_median result <- p_median(   demand = demand,   facilities = candidates,   n_facilities = 5,   weight_col = \"population\",   cost_matrix = ttm )"},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Ward Spatial Clustering — ward_spatial","title":"Ward Spatial Clustering — ward_spatial","text":"Performs spatially-constrained hierarchical clustering using Ward's minimum variance method. spatially contiguous areas can merged, ensuring resulting regions spatially connected.","code":""},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ward Spatial Clustering — ward_spatial","text":"","code":"ward_spatial(   data,   attrs = NULL,   n_regions,   weights = \"queen\",   bridge_islands = FALSE,   scale = TRUE,   verbose = FALSE )"},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ward Spatial Clustering — ward_spatial","text":"data sf object polygon point geometries. attrs Character vector column names use clustering (e.g., c(\"var1\", \"var2\")). NULL, uses numeric columns. n_regions Integer. Number regions (clusters) create. weights Spatial weights specification. Can : \"queen\" (default): Polygons sharing boundary point neighbors \"rook\": Polygons sharing edge neighbors nb object spdep created sp_weights() list weight types: list(type = \"knn\", k = 6) k-nearest neighbors, list(type = \"distance\", d = 5000) distance-based weights bridge_islands Logical. TRUE, automatically connect disconnected components (e.g., islands) using nearest-neighbor edges. FALSE (default), function error spatial weights graph disconnected. scale Logical. TRUE (default), standardize attributes clustering. verbose Logical. Print progress messages.","code":""},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ward Spatial Clustering — ward_spatial","text":"sf object .region column containing cluster assignments. Metadata stored \"spopt\" attribute.","code":""},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ward Spatial Clustering — ward_spatial","text":"function implements spatially-constrained agglomerative hierarchical clustering using Ward's minimum variance criterion. Unlike standard Ward clustering, version enforces spatial contiguity allowing clusters share border merged. algorithm: Starts observation cluster step, finds pair adjacent clusters minimum Ward distance (increase total within-cluster variance) Merges single cluster Repeats desired number regions reached result guarantees regions spatially contiguous.","code":""},{"path":"https://walker-data.com/spopt/reference/ward_spatial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ward Spatial Clustering — ward_spatial","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) nc <- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))  # Cluster into 8 spatially-contiguous regions result <- ward_spatial(nc, attrs = c(\"SID74\", \"SID79\"), n_regions = 8) plot(result[\".region\"]) } # }"}]
